{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am3052/.conda/envs/elk/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 1024\n",
    "\n",
    "# Train set indices which contain examples that will be tokenized\n",
    "# to longer than MAX_LENGTH\n",
    "INVALID_INDICES = [\n",
    "    4050, 5584, 11484, 12970, 16268,\n",
    "    17807, 27560, 27891, 31253, 46463,\n",
    "    50176, 53368, 58029, 58571, 60007,\n",
    "    63541, 64250, 72894, 73473, 74163\n",
    "]\n",
    "len(INVALID_INDICES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/rds/user/am3052/hpc-work/elk-rlhf/notebooks/../../.hf_cache/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'chosen', 'rejected'],\n",
       "    num_rows: 5103\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Dahoas/rm-static\", cache_dir=\"../../.hf_cache/datasets\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'response', 'chosen', 'rejected'],\n",
       "        num_rows: 76236\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'response', 'chosen', 'rejected'],\n",
       "        num_rows: 5103\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].filter(lambda item, idx: idx not in INVALID_INDICES, with_indices=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06273743222808247"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"].num_rows / (dataset[\"train\"].num_rows + dataset[\"test\"].num_rows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6b\")\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([183, 135],\n",
       " ['chosen', 'rejected'],\n",
       " tensor([[  198,   198, 20490,    25,  1680,   345,  6901,   262,  4831,   284]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_row(row, tokenizer, max_length=1024):\n",
    "    prompt = row[\"prompt\"]\n",
    "    chosen_response, rejected_response = row[\"chosen\"], row[\"rejected\"]\n",
    "\n",
    "    chosen_tokenized = tokenizer(\n",
    "        prompt + chosen_response + EOS_TOKEN, return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    rejected_tokenized = tokenizer(\n",
    "        prompt + rejected_response + EOS_TOKEN, return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    return { \"chosen\": chosen_tokenized, \"rejected\": rejected_tokenized }\n",
    "\n",
    "tokenized_text = tokenize_row(dataset[\"train\"][0], tokenizer)\n",
    "list(map(lambda x: x.shape[1], tokenized_text.values())), list(tokenized_text.keys()), tokenized_text[\"chosen\"][:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /rds/user/am3052/hpc-work/.hf_cache/datasets/Dahoas___parquet/default-b9d2c4937d617106/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-5e48db60fca6235f.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'response', 'chosen', 'rejected'],\n",
       "        num_rows: 76236\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'response', 'chosen', 'rejected'],\n",
       "        num_rows: 5103\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize_row, fn_kwargs={ \"tokenizer\": tokenizer })\n",
    "dataset[\"test\"] = dataset[\"test\"].map(tokenize_row, fn_kwargs={ \"tokenizer\": tokenizer })\n",
    "# dataset = dataset.remove_columns([\"prompt\", \"response\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant:',\n",
       " 'response': ' Yes, you can do that to help the cloth pick up even more dirt from the screen. Be sure to always use a clean, soft cloth, not a piece of scratchy, roughened, or textured material, and make sure it’s lint-free.',\n",
       " 'chosen': [[198,\n",
       "   198,\n",
       "   20490,\n",
       "   25,\n",
       "   1680,\n",
       "   345,\n",
       "   6901,\n",
       "   262,\n",
       "   4831,\n",
       "   284,\n",
       "   3424,\n",
       "   34290,\n",
       "   290,\n",
       "   895,\n",
       "   463,\n",
       "   3212,\n",
       "   422,\n",
       "   257,\n",
       "   13224,\n",
       "   3159,\n",
       "   198,\n",
       "   198,\n",
       "   48902,\n",
       "   25,\n",
       "   3363,\n",
       "   11,\n",
       "   3729,\n",
       "   13,\n",
       "   1675,\n",
       "   3424,\n",
       "   534,\n",
       "   3159,\n",
       "   11,\n",
       "   345,\n",
       "   717,\n",
       "   761,\n",
       "   284,\n",
       "   779,\n",
       "   257,\n",
       "   4580,\n",
       "   69,\n",
       "   1856,\n",
       "   16270,\n",
       "   393,\n",
       "   2705,\n",
       "   11,\n",
       "   21151,\n",
       "   16270,\n",
       "   284,\n",
       "   15165,\n",
       "   19916,\n",
       "   866,\n",
       "   262,\n",
       "   4417,\n",
       "   286,\n",
       "   262,\n",
       "   3159,\n",
       "   13,\n",
       "   7406,\n",
       "   11,\n",
       "   345,\n",
       "   447,\n",
       "   247,\n",
       "   297,\n",
       "   765,\n",
       "   284,\n",
       "   5552,\n",
       "   257,\n",
       "   2705,\n",
       "   11,\n",
       "   300,\n",
       "   600,\n",
       "   12,\n",
       "   5787,\n",
       "   11,\n",
       "   4580,\n",
       "   69,\n",
       "   1856,\n",
       "   12724,\n",
       "   16270,\n",
       "   290,\n",
       "   15165,\n",
       "   6437,\n",
       "   340,\n",
       "   736,\n",
       "   290,\n",
       "   6071,\n",
       "   1973,\n",
       "   262,\n",
       "   3159,\n",
       "   284,\n",
       "   4781,\n",
       "   34290,\n",
       "   290,\n",
       "   895,\n",
       "   463,\n",
       "   3212,\n",
       "   13,\n",
       "   198,\n",
       "   198,\n",
       "   20490,\n",
       "   25,\n",
       "   1680,\n",
       "   314,\n",
       "   11662,\n",
       "   318,\n",
       "   404,\n",
       "   1773,\n",
       "   2645,\n",
       "   5548,\n",
       "   4291,\n",
       "   262,\n",
       "   16270,\n",
       "   290,\n",
       "   3424,\n",
       "   340,\n",
       "   326,\n",
       "   835,\n",
       "   30,\n",
       "   198,\n",
       "   198,\n",
       "   48902,\n",
       "   25,\n",
       "   3363,\n",
       "   11,\n",
       "   345,\n",
       "   460,\n",
       "   466,\n",
       "   326,\n",
       "   284,\n",
       "   1037,\n",
       "   262,\n",
       "   16270,\n",
       "   2298,\n",
       "   510,\n",
       "   772,\n",
       "   517,\n",
       "   13647,\n",
       "   422,\n",
       "   262,\n",
       "   3159,\n",
       "   13,\n",
       "   1355,\n",
       "   1654,\n",
       "   284,\n",
       "   1464,\n",
       "   779,\n",
       "   257,\n",
       "   3424,\n",
       "   11,\n",
       "   2705,\n",
       "   16270,\n",
       "   11,\n",
       "   407,\n",
       "   257,\n",
       "   3704,\n",
       "   286,\n",
       "   12692,\n",
       "   88,\n",
       "   11,\n",
       "   13805,\n",
       "   70,\n",
       "   831,\n",
       "   276,\n",
       "   11,\n",
       "   393,\n",
       "   2420,\n",
       "   1522,\n",
       "   2587,\n",
       "   11,\n",
       "   290,\n",
       "   787,\n",
       "   1654,\n",
       "   340,\n",
       "   447,\n",
       "   247,\n",
       "   82,\n",
       "   300,\n",
       "   600,\n",
       "   12,\n",
       "   5787,\n",
       "   13,\n",
       "   50256]],\n",
       " 'rejected': [[198,\n",
       "   198,\n",
       "   20490,\n",
       "   25,\n",
       "   1680,\n",
       "   345,\n",
       "   6901,\n",
       "   262,\n",
       "   4831,\n",
       "   284,\n",
       "   3424,\n",
       "   34290,\n",
       "   290,\n",
       "   895,\n",
       "   463,\n",
       "   3212,\n",
       "   422,\n",
       "   257,\n",
       "   13224,\n",
       "   3159,\n",
       "   198,\n",
       "   198,\n",
       "   48902,\n",
       "   25,\n",
       "   3363,\n",
       "   11,\n",
       "   3729,\n",
       "   13,\n",
       "   1675,\n",
       "   3424,\n",
       "   534,\n",
       "   3159,\n",
       "   11,\n",
       "   345,\n",
       "   717,\n",
       "   761,\n",
       "   284,\n",
       "   779,\n",
       "   257,\n",
       "   4580,\n",
       "   69,\n",
       "   1856,\n",
       "   16270,\n",
       "   393,\n",
       "   2705,\n",
       "   11,\n",
       "   21151,\n",
       "   16270,\n",
       "   284,\n",
       "   15165,\n",
       "   19916,\n",
       "   866,\n",
       "   262,\n",
       "   4417,\n",
       "   286,\n",
       "   262,\n",
       "   3159,\n",
       "   13,\n",
       "   7406,\n",
       "   11,\n",
       "   345,\n",
       "   447,\n",
       "   247,\n",
       "   297,\n",
       "   765,\n",
       "   284,\n",
       "   5552,\n",
       "   257,\n",
       "   2705,\n",
       "   11,\n",
       "   300,\n",
       "   600,\n",
       "   12,\n",
       "   5787,\n",
       "   11,\n",
       "   4580,\n",
       "   69,\n",
       "   1856,\n",
       "   12724,\n",
       "   16270,\n",
       "   290,\n",
       "   15165,\n",
       "   6437,\n",
       "   340,\n",
       "   736,\n",
       "   290,\n",
       "   6071,\n",
       "   1973,\n",
       "   262,\n",
       "   3159,\n",
       "   284,\n",
       "   4781,\n",
       "   34290,\n",
       "   290,\n",
       "   895,\n",
       "   463,\n",
       "   3212,\n",
       "   13,\n",
       "   198,\n",
       "   198,\n",
       "   20490,\n",
       "   25,\n",
       "   1680,\n",
       "   314,\n",
       "   11662,\n",
       "   318,\n",
       "   404,\n",
       "   1773,\n",
       "   2645,\n",
       "   5548,\n",
       "   4291,\n",
       "   262,\n",
       "   16270,\n",
       "   290,\n",
       "   3424,\n",
       "   340,\n",
       "   326,\n",
       "   835,\n",
       "   30,\n",
       "   198,\n",
       "   198,\n",
       "   48902,\n",
       "   25,\n",
       "   3363,\n",
       "   11,\n",
       "   345,\n",
       "   460,\n",
       "   11662,\n",
       "   340,\n",
       "   3264,\n",
       "   4291,\n",
       "   262,\n",
       "   16270,\n",
       "   13,\n",
       "   50256]]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_idxs = []\n",
    "\n",
    "for i, sample in enumerate(dataset[\"train\"]):\n",
    "    if len(sample[\"chosen\"][0]) > MAX_LENGTH or len(sample[\"rejected\"][0]) > MAX_LENGTH:\n",
    "        bad_idxs.append(i)\n",
    "\n",
    "bad_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(dataset[\"test\"]):\n",
    "    if len(sample[\"chosen\"][0]) > MAX_LENGTH or len(sample[\"rejected\"][0]) > MAX_LENGTH:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
