{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "datasets.logging.set_verbosity_error() # Disable the logging of the datasets library\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "from fastchat.model import get_conversation_template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURNS_DATASETS = [\"glue:qnli\"]\n",
    "\n",
    "VERSION = f\"v1\"\n",
    "\n",
    "# SPLIT = \"validation\"\n",
    "SPLIT = \"train\"\n",
    "\n",
    "N_PER_DATASET = 105_000 if SPLIT == \"train\" else 1550\n",
    "\n",
    "SEED = 42 if SPLIT == \"train\" else 2023\n",
    "SEED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue:qnli\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split='train'\n",
      "104743\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for dataset_path in BURNS_DATASETS:\n",
    "    print(dataset_path)\n",
    "\n",
    "    # Parse dataset name\n",
    "    dataset_name = None    \n",
    "    if \":\" in dataset_path:\n",
    "        dataset_path, dataset_name = dataset_path.split(\":\")\n",
    "    \n",
    "    \n",
    "    # Get the most validation-like split\n",
    "    available_splits = load_dataset_builder(\n",
    "        dataset_path, name=dataset_name\n",
    "    ).info.splits.keys()\n",
    "    split = \"validation\" if \"validation\" in available_splits else \"test\"\n",
    "    split = split if SPLIT != \"train\" else \"train\"\n",
    "    print(f\"{split=}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        dataset_path, name=dataset_name, split=split,\n",
    "    )\n",
    "\n",
    "    # Get a desired subset of the data\n",
    "    n = N_PER_DATASET if dataset.num_rows > N_PER_DATASET else dataset.num_rows\n",
    "    dataset = dataset.shuffle(seed=SEED).select(range(n))\n",
    "\n",
    "    print(dataset.num_rows)\n",
    "\n",
    "    key = f\"{dataset_path}/{dataset_name}\" if dataset_name else dataset_path\n",
    "    dataset_dict[key] = dataset\n",
    "\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104743"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of examples in total in all datasets\n",
    "sum([dataset.num_rows for dataset in dataset_dict.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([len(Counter(dataset[\"label\"])) > 1 for dataset in dataset_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli: 104743\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {dataset.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli\n",
      "10000 94743\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_dataset_dict = {}\n",
    "ppo_dataset_dict = {}\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "    # test_size = 225 if dataset.num_rows > 225 else 10 # specialized for COPA\n",
    "    splits = dataset.train_test_split(train_size=10_000, seed=SEED)\n",
    "    # print(splits)\n",
    "    print(splits[\"train\"].num_rows, splits[\"test\"].num_rows)\n",
    "\n",
    "    train_dataset_dict[dataset_name] = splits[\"train\"]\n",
    "    ppo_dataset_dict[dataset_name] = splits[\"test\"]\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "94743\n"
     ]
    }
   ],
   "source": [
    "print(sum(dataset.num_rows for dataset in train_dataset_dict.values()))\n",
    "print(sum(dataset.num_rows for dataset in ppo_dataset_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.DatasetDict(train_dataset_dict).save_to_disk(\n",
    "#     f\"datasets/qnli_vicuna_train_raw_{VERSION}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.DatasetDict(ppo_dataset_dict).save_to_disk(\n",
    "#     f\"datasets/qnli_vicuna_ppo_training_raw_{VERSION}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  3 augustas Domain Users 1.0K Jul 21 22:46 qnli_vicuna_ppo_training_raw_v1\n",
      "drwxr-xr-x  3 augustas Domain Users  33K Jul 21 22:45 qnli_vicuna_train_raw_v1\n"
     ]
    }
   ],
   "source": [
    "!ls -lah datasets | grep {VERSION} | grep qnli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    glue/qnli: Dataset({\n",
       "        features: ['question', 'sentence', 'label', 'idx'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dataset_dict to test_dataset\n",
    "dataset_dict = datasets.DatasetDict.load_from_disk(\n",
    "    f\"datasets/qnli_vicuna_train_raw_{VERSION}\"\n",
    ")\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "The Quran in its present form is generally considered by academic scholars to record the words spoken by Muhammad because the search for variants has not yielded any differences of great significance.[page needed]\n",
      "```\n",
      "Question: Which which university is Fred Donner affiliated??\n",
      "Answer: ASSISTANT: No\n"
     ]
    }
   ],
   "source": [
    "def format_label(label):\n",
    "    return \"No\" if label else \"Yes\"\n",
    "\n",
    "# Dataset template\n",
    "def template(example, answer_prefix=\"Answer:\"):\n",
    "    conv = get_conversation_template(\"lmsys/vicuna-7b-v1.3\")\n",
    "\n",
    "    message = (\n",
    "        \"Consider the sentence below in triple backticks \"\n",
    "        \"and corresponding question. Does the sentence contain enough information \"\n",
    "        \"to answer the question? Your answer should be either yes or no.\\n\\n\"\n",
    "        \"Desired format:\\n\"\n",
    "        \"Answer: <your_answer>\\n\"\n",
    "        f\"Do not print \\\"{answer_prefix}\\\" again, just what you think the answer is.\\n\\n\"\n",
    "        f\"Sentence:\\n```\\n{example['sentence']}\\n```\\n\"\n",
    "        f\"Question: {example['question']}?\\n\"\n",
    "        f\"{answer_prefix}\"\n",
    "    )\n",
    "\n",
    "    conv.append_message(conv.roles[0], message)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "\n",
    "    return conv.get_prompt(), format_label(example[\"label\"])\n",
    "\n",
    "\n",
    "q, a = template(dataset[2])\n",
    "print(\" \".join([q, a]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the dataset for the chosen split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli\n",
      "CPU times: user 421 ms, sys: 15.5 ms, total: 436 ms\n",
      "Wall time: 469 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "ALLOWED_KEYS = [\"text\", \"label\", \"original_dataset\"]\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    for idx, entry in enumerate(dataset):\n",
    "        new_entry = entry.copy()\n",
    "        \n",
    "        # In case we need to know which dataset the entry came from\n",
    "        new_entry[\"original_dataset\"] = dataset_name\n",
    "\n",
    "        # Whether the sample will be truthful or not\n",
    "        is_truthful = random.choice([True, False])            \n",
    "        \n",
    "        # Apply the template\n",
    "        if not is_truthful:\n",
    "            # Untruthful binary case\n",
    "            new_entry[\"label\"] = 1 - new_entry[\"label\"]\n",
    "        new_text = \" \".join(template(new_entry))\n",
    "\n",
    "        new_entry[\"text\"] = new_text\n",
    "\n",
    "        # We can now change the label to whether the sample is truthful or not\n",
    "        new_entry[\"label\"] = int(is_truthful)\n",
    "\n",
    "        # Remove all other keys\n",
    "        new_entry = { k: v for k, v in new_entry.items() if k in ALLOWED_KEYS }\n",
    "\n",
    "        # Append to the new dataset\n",
    "        new_dataset.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'original_dataset', 'text'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = datasets.Dataset.from_list(new_dataset)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'original_dataset': 'glue/qnli',\n",
       " 'text': 'A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\\'s questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\\n\\nDesired format:\\nAnswer: <your_answer>\\nDo not print \"Answer:\" again, just what you think the answer is.\\n\\nSentence:\\n```\\nModern web browsers support a combination of standards-based and de facto HTML and XHTML, which should be rendered in the same way by all browsers.\\n```\\nQuestion: HTML and XHTML should be what by all browsers??\\nAnswer: ASSISTANT: Yes'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_idx = 0\n",
    "my_dataset[current_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Over time, Roman architecture was modified as their urban requirements changed, and the civil engineering and building construction technology became developed and refined.\n",
      "```\n",
      "Question: Do any Roman structures still exist in our time??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Since the 2015 council elections, the composition of the council is:\n",
      "```\n",
      "Question: In what month are council elections held??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "ARFORGEN is the Army Force Generation process approved in 2006 to meet the need to continuously replenish forces for deployment, at unit level, and for other echelons as required by the mission.\n",
      "```\n",
      "Question: Where is the Joint Multinational Training Center located??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "The name may refer both to Balts and Slavs.\n",
      "```\n",
      "Question: What name may refer both to Balts and Slavs??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "lupus baileyi, and coyote Canis latrans.\n",
      "```\n",
      "Question: Canis latrans is what animal??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Train travel is well established in the Alps, with, for instance 120 km (75 mi) of track for every 1,000 km2 (390 sq mi) in a country such as Switzerland.\n",
      "```\n",
      "Question: Where are most of Europe's highest railways located??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=0\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Costing $16.3 million, the prefabricated station, which is part of the International Polar Year, was shipped to the South Pole from Belgium by the end of 2008 to monitor the health of the polar regions.\n",
      "```\n",
      "Question: How much did the Princess Elizabeth station cost??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "China desperately needed the economic and military aid promised by the Soviets.\n",
      "```\n",
      "Question: Who needed Soviet financial and military aid??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=0\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "After the success of his song \"Jesus Walks\" from the album\n",
      "```\n",
      "Question: September of 2014, Kanye called himself a what during one of his concerts??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=0\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Together, Steele and Addison published The Spectator (1711), a daily publication which aimed, through fictional narrator Mr. Spectator, both to entertain and to provoke discussion regarding serious philosophical matters.\n",
      "```\n",
      "Question: In what year was The Spectator published??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for current_index in range(10, 20):\n",
    "    print(f\"label={my_dataset[current_index]['label']}\")\n",
    "    print(my_dataset[current_index][\"text\"])\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 5016, 1: 4984}), Counter({'glue/qnli': 10000}))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(my_dataset[\"label\"]), Counter(my_dataset[\"original_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dataset.to_parquet(f\"datasets/qnli_vicuna_{SPLIT}_{VERSION}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  3 augustas Domain Users  25K Jul 21 22:46 qnli_vicuna_ppo_training_raw_v1\n",
      "drwxr-xr-x  3 augustas Domain Users  33K Jul 21 22:45 qnli_vicuna_train_raw_v1\n",
      "-rw-r--r--  1 augustas Domain Users 2.0M Jul 21 23:02 qnli_vicuna_train_v1.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lah datasets | grep {VERSION} | grep qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
