{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "from utils import replace_text_with_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/fsx/home-augustas/elk')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELK_PATH = Path(\"../../../elk/\")\n",
    "ELK_PATH.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/fsx/home-augustas/elk/elk/promptsource', '/fsx/home-augustas/elk']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [\n",
    "    ELK_PATH,\n",
    "    ELK_PATH / \"elk\" / \"promptsource\",\n",
    "]\n",
    "\n",
    "for module in modules:\n",
    "    if not str(module) in sys.path:\n",
    "        sys.path.insert(0, str(module.resolve()))\n",
    "\n",
    "sys.path[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the logging of the datasets library\n",
    "import datasets\n",
    "\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all datasets used in Burns et al. (2022) (apart from story_cloze)\n",
    "# BURNS_DATASETS = [\n",
    "#     \"ag_news\",\n",
    "#     \"amazon_polarity\",\n",
    "#     \"dbpedia_14\",\n",
    "#     \"glue:qnli\",\n",
    "#     \"imdb\",\n",
    "#     \"piqa\",\n",
    "#     \"super_glue:boolq\",\n",
    "#     \"super_glue:copa\",\n",
    "#     \"super_glue:rte\",\n",
    "# ]\n",
    "BURNS_DATASETS = [\"piqa\"]\n",
    "\n",
    "VERSION = f\"v2\"\n",
    "\n",
    "SPLIT = \"validation\"\n",
    "# SPLIT = \"train\"\n",
    "\n",
    "# These numbers are chosen so that both datasets have\n",
    "# approximately 10k examples in total (probably a bit less for train split)\n",
    "N_PER_DATASET = 17000 if SPLIT == \"train\" else 2000\n",
    "if SPLIT == \"train\":\n",
    "    # assert N_PER_DATASET <= 2490, \"N_PER_DATASET must be <= 2490\"\n",
    "    assert N_PER_DATASET <= 25000, \"N_PER_DATASET must be <= 2490\"\n",
    "else:\n",
    "    assert N_PER_DATASET <= 2000, \"N_PER_DATASET must be <= 1838\"\n",
    "\n",
    "SEED = 42 if SPLIT == \"train\" else 2023\n",
    "SEED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for dataset_path in BURNS_DATASETS:\n",
    "    print(dataset_path)\n",
    "\n",
    "    # Parse dataset name\n",
    "    dataset_name = None    \n",
    "    if \":\" in dataset_path:\n",
    "        dataset_path, dataset_name = dataset_path.split(\":\")\n",
    "    \n",
    "    \n",
    "    # Get the most validation-like split\n",
    "    available_splits = load_dataset_builder(\n",
    "        dataset_path, name=dataset_name\n",
    "    ).info.splits.keys()\n",
    "    split = \"validation\" if \"validation\" in available_splits else \"test\"\n",
    "    split = split if SPLIT != \"train\" else \"train\"\n",
    "    print(split)\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        dataset_path, name=dataset_name, split=split,\n",
    "    )\n",
    "\n",
    "    # Get a desired subset of the data\n",
    "    n = N_PER_DATASET if dataset.num_rows > N_PER_DATASET else dataset.num_rows\n",
    "    dataset = dataset.shuffle(seed=SEED).select(range(n))\n",
    "\n",
    "    key = f\"{dataset_path}/{dataset_name}\" if dataset_name else dataset_path\n",
    "    dataset_dict[key] = dataset\n",
    "\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([len(Counter(dataset[\"label\"])) > 1 for dataset in dataset_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 1838\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {dataset.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template_dict = {}\n",
    "\n",
    "for dataset_path in dataset_dict.keys():\n",
    "    dataset_templates = DatasetTemplates(dataset_path)\n",
    "\n",
    "    dataset_templates.templates = {\n",
    "        x.name: x for x in dataset_templates.templates.values() if x.get_answer_choices_list(dataset_dict[dataset_path][0]) is not None\n",
    "    }\n",
    "\n",
    "    dataset_template_dict[dataset_path] = dataset_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 7\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"ag_news\"\n",
    "# for idx, (template_name, template) in enumerate(dataset_template_dict[dataset_name].templates.items()):\n",
    "#     print(f\"{idx+1}) {dataset_name}/{template_name}: {template.metadata.choices_in_prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 7\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    good_templates = [x for x in dataset_templates.templates.values() if x.metadata.choices_in_prompt]\n",
    "    good_templates = [x for x in dataset_templates.templates.values() if \"burns\" not in x.name]\n",
    "    print(f\"{dataset_name}: {len(good_templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 6\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_template_dict:\n",
    "    good_templates = {\n",
    "        name: x for name, x in dataset_template_dict[dataset_name].templates.items() if x.metadata.choices_in_prompt\n",
    "    }\n",
    "    dataset_template_dict[dataset_name].templates = good_templates\n",
    "    print(f\"{dataset_name}: {len(good_templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 6\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"super_glue/rte\"\n",
    "# dataset_name = \"glue/qnli\"\n",
    "\n",
    "# for template_name, template in dataset_template_dict[dataset_name].templates.items():\n",
    "#     # print(template_name)\n",
    "#     # print(dataset_dict[dataset_name][0])\n",
    "#     q, a = template.apply(\n",
    "#         dataset_dict[dataset_name][1]\n",
    "#     )\n",
    "#     # print(q == q.strip())\n",
    "#     # print(a == a.strip())\n",
    "#     # print(\" \".join([q, a.strip()]))\n",
    "#     print(\" \".join([q, a]))\n",
    "#     print(len(a))\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the dataset for the chosen split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_fixed_answer_choices_list()}\")\n",
    "\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_answer_choices_list(dataset_dict[dataset_name][0])}\")\n",
    "\n",
    "#     print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa: 6\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa\n",
      "CPU times: user 4.34 s, sys: 35.7 ms, total: 4.37 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "ALLOWED_KEYS = [\"text\", \"label\", \"original_dataset\", \"template_name\"]\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    for idx, entry in enumerate(dataset):\n",
    "        new_entry = entry.copy()\n",
    "        \n",
    "        # In case we need to know which dataset the entry came from\n",
    "        new_entry[\"original_dataset\"] = dataset_name\n",
    "\n",
    "        # Sample a random template\n",
    "        template_name = random.choice(\n",
    "            list(dataset_template_dict[dataset_name].templates.keys())\n",
    "        )\n",
    "        template = dataset_template_dict[dataset_name].templates[template_name]\n",
    "        new_entry[\"template_name\"] = template_name\n",
    "\n",
    "        # Whether the sample will be truthful or not\n",
    "        is_truthful = random.choice([True, False])\n",
    "\n",
    "        # If not truthful, sample a random incorrect label\n",
    "        if not is_truthful and len(dataset.features[\"label\"].names) > 2:\n",
    "            label_mappping = dataset.features[\"label\"] # [class 1, class 2, ...]\n",
    "            all_label_ids = [label_mappping.str2int(x) for x in label_mappping.names] # [0, 1, ...]\n",
    "            incorrect_label_id = all_label_ids[(1 - new_entry[\"label\"]) % len(all_label_ids)]\n",
    "            incorrect_label = template.get_fixed_answer_choices_list()[incorrect_label_id]\n",
    "            \n",
    "        \n",
    "        # Apply the template\n",
    "        if is_truthful:\n",
    "            # new_text = \" \".join(template.apply(new_entry))\n",
    "            q, a = template.apply(new_entry)\n",
    "            new_text = \" \".join([q.rstrip(), a.strip()])\n",
    "        elif not is_truthful and len(dataset.features[\"label\"].names) > 2:\n",
    "            q, a = template.apply(new_entry)\n",
    "            incorrect_label = replace_text_with_whitespace(a, incorrect_label)\n",
    "            new_text = \" \".join([q, incorrect_label])\n",
    "        else:\n",
    "            # Untruthful binary case\n",
    "            new_entry[\"label\"] = 1 - new_entry[\"label\"]\n",
    "            # new_text = \" \".join(template.apply(new_entry))\n",
    "            q, a = template.apply(new_entry)\n",
    "            new_text = \" \".join([q.rstrip(), a.strip()])\n",
    "\n",
    "        new_entry[\"text\"] = new_text\n",
    "\n",
    "        # We can now change the label to whether the sample is truthful or not\n",
    "        new_entry[\"label\"] = int(is_truthful)\n",
    "\n",
    "        # Remove all other keys\n",
    "        new_entry = { k: v for k, v in new_entry.items() if k in ALLOWED_KEYS }\n",
    "\n",
    "        # Append to the new dataset\n",
    "        new_dataset.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'original_dataset', 'template_name', 'text'],\n",
       "    num_rows: 1838\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = datasets.Dataset.from_list(new_dataset)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'original_dataset': 'piqa',\n",
       " 'template_name': 'finish_sentence_with_correct_choice',\n",
       " 'text': 'Finish the following sentence with the best choice: protractor\\n\\nChoices:\\n- can stab pill bug \\n- can stab leopard \\n\\nAnswer: can stab leopard'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_idx = 0\n",
    "my_dataset[current_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am shocked and amazed to find reviews short of miserable for this horrible film. I rented this \"movie\" or feces, whatever you wish to call it, with several friends and after thirty minutes we had to stop watching. Just listening to the dialog left a horrible taste of sour milk in my mouth. This film was about as intelligent as an ass pimple.I hope I never see that bra-less, raggedy Anne look alike (Julianne Nicholson) again.It was like watching the most putrid pilot for a sitcom that will never make it to television, but instead of being a quick but painful 30 minutes( all I could bare)this was an excruciating 90 minutes.\n",
      "\n",
      "What is the sentiment expressed in this text?\n",
      "\n",
      " positive\n"
     ]
    }
   ],
   "source": [
    "# It's unbelievable but the fourth is better\n",
    "# The following movie review expresses what\n",
    "# I was going to use 'The German Scream' as a summary\n",
    "# This movie is by far one of the worst B-movies\n",
    "# At the very beginning, the look at a control\n",
    "print(my_dataset[current_idx][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=1\n",
      "Does this phrase make sense?\n",
      "To freshen up an old sponge, soak it in hot water for a bit.\n",
      "Answer with Yes or No No\n",
      "---------------------------------\n",
      "label=1\n",
      "Solution 1: Your stencil should look like a simplified version of the original design.If your using a computer,you can get this done by using with the editing program and play around with the settings.\n",
      "Solution 2: Your stencil should look like a simplified version of the original design.If your using a computer,you can get this done by using with the playing program and play around with the settings.\n",
      "\n",
      "Goal: How do I get an airbrush painting onto the material surface?\n",
      "\n",
      "Given the goal, what is the correct solution?\n",
      "\n",
      "Answer by copying the correct solution Your stencil should look like a simplified version of the original design.If your using a computer,you can get this done by using with the editing program and play around with the settings.\n",
      "---------------------------------\n",
      "label=0\n",
      "Finish the following sentence with the best choice: What flavoring do I need to make indian kheer?\n",
      "\n",
      "Choices:\n",
      "- You need almonds, cashews, saffron, cardamom, coconut and dishwasher detergent.\n",
      "- You need almonds, cashews, saffron, cardamom, coconut and raisins\n",
      "\n",
      "Answer: You need almonds, cashews, saffron, cardamom, coconut and dishwasher detergent.\n",
      "---------------------------------\n",
      "label=0\n",
      "Given a goal and 2 solutions, choose the most appropriate solution.\n",
      "Goal: How to make a poncho hood tent?\n",
      "- Solution 1: Affix the loop-ended 4’ cords to the top of your poncho. Pound in stakes near to where the corners will be. If the stakes don’t hold, use a large rock. You will tie-off the cords to the stakes at the 1’-2’ position. Shove the handles of both trekking poles into the hood of the poncho, extend them as needed, and spike the other end into the ground. Stake in the corners.\n",
      "- Solution 2: Affix the loop-ended 4’ cords to each corner of your poncho. Pound in stakes near to where the corners will be. If the stakes don’t hold, use a large rock. You will tie-off the cords to the stakes at the 1’-2’ position. Shove the handles of both trekking poles into the hood of the poncho, extend them as needed, and spike the other end into the ground. Stake in the corners.\n",
      "\n",
      "Answer by returning either Solution 1 or Solution 2 Solution 1\n",
      "---------------------------------\n",
      "label=1\n",
      "Given a goal and 2 solutions, choose the most appropriate solution.\n",
      "Goal: How can I marinate venison steaks?\n",
      "- Solution 1: Mix all ingredients together in a colander and let sit for 10 to 30 minutes.\n",
      "- Solution 2: Mix all ingredients in a glass bowl and let sit for 10 to 30 minutes.\n",
      "\n",
      "Answer by returning either Solution 1 or Solution 2 Solution 2\n",
      "---------------------------------\n",
      "label=0\n",
      "Goal: chalk\n",
      "\n",
      "Which is the correct ending?\n",
      "- can easily be broke with tin foil \n",
      "- can easily be broke with fist \n",
      "\n",
      "Answer: can easily be broke with tin foil\n",
      "---------------------------------\n",
      "label=1\n",
      "Finish the following sentence with the best choice: To cook the kebab meat on a grill\n",
      "\n",
      "Choices:\n",
      "- Place the kebab meat on the grill.\n",
      "- Skewer the meat and put on grill.\n",
      "\n",
      "Answer: Skewer the meat and put on grill.\n",
      "---------------------------------\n",
      "label=1\n",
      "Goal: How do you remove mortar from a brick to recycle it (the brick)?\n",
      "\n",
      "Which is the correct ending?\n",
      "- While holding the brick in one hand, hold a hammer in your other hand and gently tap the mortar to un-stick it from the brick.\n",
      "- While holding the brick in one hand, hold a second brick in your other hand and forcefully hit the two bricks together.\n",
      "\n",
      "Answer: While holding the brick in one hand, hold a hammer in your other hand and gently tap the mortar to un-stick it from the brick.\n",
      "---------------------------------\n",
      "label=1\n",
      "Does this phrase make sense?\n",
      "Avoid frozen wiper blades. fill car with cold weather rated wiper fluid.\n",
      "Answer with Yes or No Yes\n",
      "---------------------------------\n",
      "label=1\n",
      "Given a goal and 2 solutions, choose the most appropriate solution.\n",
      "Goal: blanket\n",
      "- Solution 1: can cover a sofa from dirt\n",
      "- Solution 2: can make a sofa invisible\n",
      "\n",
      "Answer by returning either Solution 1 or Solution 2 Solution 1\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for current_index in range(10, 20):\n",
    "    print(f\"label={my_dataset[current_index]['label']}\")\n",
    "    print(my_dataset[current_index][\"text\"])\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 929, 1: 909}), Counter({'piqa': 1838}))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counter({0: 755, 1: 745})\n",
    "# Counter({1: 750, 0: 750})\n",
    "# Counter({0: 774, 1: 726}\n",
    "# Counter({0: 752, 1: 748})\n",
    "# Counter({0: 765, 1: 735})\n",
    "Counter(my_dataset[\"label\"]), Counter(my_dataset[\"original_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b5bf17f23b4353b019a924a83d6ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "774669"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_dataset.to_parquet(f\"datasets/burns_datasets_VINC_{SPLIT}_{VERSION}.parquet\")\n",
    "# my_dataset.to_parquet(f\"datasets/burns_datasets_VINC_imdb_{SPLIT}_{VERSION}.parquet\")\n",
    "# my_dataset.to_parquet(f\"datasets/wrapped_piqa_{SPLIT}_{VERSION}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  3 augustas Domain Users  25K Jul 24 20:31 wrapped_piqa_ppo_training_raw_v2\n",
      "-rw-r--r--  1 augustas Domain Users 972K Jul 24 21:26 wrapped_piqa_ppo_training_v2.parquet\n",
      "drwxr-xr-x  3 augustas Domain Users  33K Jul 24 20:31 wrapped_piqa_train_raw_v2\n",
      "-rw-r--r--  1 augustas Domain Users 1.4M Jul 24 21:36 wrapped_piqa_train_v2.parquet\n",
      "-rw-r--r--  1 augustas Domain Users 246K Jul 24 21:41 wrapped_piqa_validation_v2.parquet\n"
     ]
    }
   ],
   "source": [
    "# !ls -lah datasets | grep {VERSION}\n",
    "# !ls -lah datasets | grep {VERSION} | grep imdb\n",
    "!ls -lah datasets | grep {VERSION} | grep piqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet_data_files = {\n",
    "#     \"train\": \"datasets/my_dataset_train.parquet\",\n",
    "#     \"validation\": \"datasets/my_dataset_validation.parquet\",\n",
    "# }\n",
    "\n",
    "# my_dataset = load_dataset(\"parquet\", data_files=parquet_data_files)\n",
    "# my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
