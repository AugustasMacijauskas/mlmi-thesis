{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "from utils import replace_text_with_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/rds/user/am3052/hpc-work/elk')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELK_PATH = Path(\"../../../elk/\")\n",
    "ELK_PATH.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/rds/user/am3052/hpc-work/elk/elk/promptsource',\n",
       " '/rds/user/am3052/hpc-work/elk']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [\n",
    "    ELK_PATH,\n",
    "    ELK_PATH / \"elk\" / \"promptsource\",\n",
    "]\n",
    "\n",
    "for module in modules:\n",
    "    if not str(module) in sys.path:\n",
    "        sys.path.insert(0, str(module.resolve()))\n",
    "\n",
    "sys.path[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the logging of the datasets library\n",
    "import datasets\n",
    "\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all datasets used in Burns et al. (2022) (apart from story_cloze)\n",
    "BURNS_DATASETS = [\n",
    "    \"ag_news\",\n",
    "    \"amazon_polarity\",\n",
    "    \"dbpedia_14\",\n",
    "    \"glue:qnli\",\n",
    "    \"imdb\",\n",
    "    \"piqa\",\n",
    "    \"super_glue:boolq\",\n",
    "    \"super_glue:copa\",\n",
    "    \"super_glue:rte\",\n",
    "]\n",
    "\n",
    "SPLIT = \"validation\"\n",
    "\n",
    "# These numbers are chosen so that both datasets have\n",
    "# approximately 10k examples in total\n",
    "N_PER_DATASET = 1200 if SPLIT == \"train\" else 1800\n",
    "if SPLIT == \"train\":\n",
    "    assert N_PER_DATASET <= 2490, \"N_PER_DATASET must be <= 2490 for train\"\n",
    "else:\n",
    "    assert N_PER_DATASET <= 1838, \"N_PER_DATASET must be <= 1838 for validation\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news\n",
      "split='test'\n",
      "1800\n",
      "-----------------------------------\n",
      "amazon_polarity\n",
      "split='test'\n",
      "1800\n",
      "-----------------------------------\n",
      "dbpedia_14\n",
      "split='test'\n",
      "1800\n",
      "-----------------------------------\n",
      "glue:qnli\n",
      "split='validation'\n",
      "1800\n",
      "-----------------------------------\n",
      "imdb\n",
      "split='test'\n",
      "1800\n",
      "-----------------------------------\n",
      "piqa\n",
      "split='validation'\n",
      "1800\n",
      "-----------------------------------\n",
      "super_glue:boolq\n",
      "split='validation'\n",
      "1800\n",
      "-----------------------------------\n",
      "super_glue:copa\n",
      "split='validation'\n",
      "100\n",
      "-----------------------------------\n",
      "super_glue:rte\n",
      "split='validation'\n",
      "277\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for dataset_path in BURNS_DATASETS:\n",
    "    print(dataset_path)\n",
    "\n",
    "    # Parse dataset name\n",
    "    dataset_name = None    \n",
    "    if \":\" in dataset_path:\n",
    "        dataset_path, dataset_name = dataset_path.split(\":\")\n",
    "    \n",
    "    \n",
    "    # Get the most validation-like split\n",
    "    available_splits = load_dataset_builder(\n",
    "        dataset_path, name=dataset_name\n",
    "    ).info.splits.keys()\n",
    "    split = \"validation\" if \"validation\" in available_splits else \"test\"\n",
    "    split = split if SPLIT != \"train\" else \"train\"\n",
    "    print(f\"{split=}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        dataset_path, name=dataset_name, split=split,\n",
    "    )\n",
    "\n",
    "    # Get a desired subset of the data\n",
    "    n = N_PER_DATASET if dataset.num_rows > N_PER_DATASET else dataset.num_rows\n",
    "    dataset = dataset.shuffle(seed=42).select(range(n))\n",
    "\n",
    "    print(dataset.num_rows)\n",
    "\n",
    "    key = f\"{dataset_path}/{dataset_name}\" if dataset_name else dataset_path\n",
    "    dataset_dict[key] = dataset\n",
    "\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([len(Counter(dataset[\"label\"])) > 1 for dataset in dataset_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 1800\n",
      "amazon_polarity: 1800\n",
      "dbpedia_14: 1800\n",
      "glue/qnli: 1800\n",
      "imdb: 1800\n",
      "piqa: 1800\n",
      "super_glue/boolq: 1800\n",
      "super_glue/copa: 100\n",
      "super_glue/rte: 277\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {dataset.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 4\n",
      "amazon_polarity: 2\n",
      "dbpedia_14: 14\n",
      "glue/qnli: 2\n",
      "imdb: 2\n",
      "piqa: 2\n",
      "super_glue/boolq: 2\n",
      "super_glue/copa: 2\n",
      "super_glue/rte: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news\n",
      "1404 396\n",
      "-----------------------------------\n",
      "amazon_polarity\n",
      "1404 396\n",
      "-----------------------------------\n",
      "dbpedia_14\n",
      "1404 396\n",
      "-----------------------------------\n",
      "glue/qnli\n",
      "1404 396\n",
      "-----------------------------------\n",
      "imdb\n",
      "1404 396\n",
      "-----------------------------------\n",
      "piqa\n",
      "1404 396\n",
      "-----------------------------------\n",
      "super_glue/boolq\n",
      "1404 396\n",
      "-----------------------------------\n",
      "super_glue/copa\n",
      "78 22\n",
      "-----------------------------------\n",
      "super_glue/rte\n",
      "216 61\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "ppo_dataset_dict = {}\n",
    "test_dataset_dict = {}\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "    splits = dataset.train_test_split(test_size=0.22, seed=42)\n",
    "    # print(splits)\n",
    "    print(splits[\"train\"].num_rows, splits[\"test\"].num_rows)\n",
    "\n",
    "    ppo_dataset_dict[dataset_name] = splits[\"train\"]\n",
    "    test_dataset_dict[dataset_name] = splits[\"test\"]\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10122, 2855)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in ppo_dataset_dict.values()), sum(dataset.num_rows for dataset in test_dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.DatasetDict(test_dataset_dict).save_to_disk(\"datasets/test_dataset_raw\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    ag_news: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    amazon_polarity: Dataset({\n",
       "        features: ['label', 'title', 'content'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    dbpedia_14: Dataset({\n",
       "        features: ['label', 'title', 'content'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    glue/qnli: Dataset({\n",
       "        features: ['question', 'sentence', 'label', 'idx'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    imdb: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    piqa: Dataset({\n",
       "        features: ['goal', 'sol1', 'sol2', 'label'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    super_glue/boolq: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    super_glue/copa: Dataset({\n",
       "        features: ['premise', 'choice1', 'choice2', 'question', 'idx', 'label'],\n",
       "        num_rows: 22\n",
       "    })\n",
       "    super_glue/rte: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'idx', 'label'],\n",
       "        num_rows: 61\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dataset_dict to test_dataset\n",
    "dataset_dict = datasets.DatasetDict.load_from_disk(\"datasets/test_dataset_raw\")\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 4\n",
      "amazon_polarity: 2\n",
      "dbpedia_14: 14\n",
      "glue/qnli: 2\n",
      "imdb: 2\n",
      "piqa: 2\n",
      "super_glue/boolq: 2\n",
      "super_glue/copa: 2\n",
      "super_glue/rte: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template_dict = {}\n",
    "\n",
    "for dataset_path in dataset_dict.keys():\n",
    "    dataset_templates = DatasetTemplates(dataset_path)\n",
    "\n",
    "    dataset_templates.templates = {\n",
    "        x.name: x for x in dataset_templates.templates.values() if x.get_answer_choices_list(dataset_dict[dataset_path][0]) is not None\n",
    "    }\n",
    "\n",
    "    dataset_template_dict[dataset_path] = dataset_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 15\n",
      "amazon_polarity: 11\n",
      "dbpedia_14: 11\n",
      "glue/qnli: 5\n",
      "imdb: 13\n",
      "piqa: 7\n",
      "super_glue/boolq: 10\n",
      "super_glue/copa: 9\n",
      "super_glue/rte: 11\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"ag_news\"\n",
    "\n",
    "# for template_name, template in dataset_template_dict[dataset_name].templates.items():\n",
    "#     # print(template_name)\n",
    "#     # print(dataset_dict[dataset_name][0])\n",
    "#     q, a = template.apply(\n",
    "#         dataset_dict[dataset_name][0]\n",
    "#     )\n",
    "#     # print(q == q.strip())\n",
    "#     # print(a == a.strip())\n",
    "#     # print(\" \".join([q, a.strip()]))\n",
    "#     print(\" \".join([q, a]))\n",
    "#     print(\"---------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the dataset for the chosen split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_fixed_answer_choices_list()}\")\n",
    "\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_answer_choices_list(dataset_dict[dataset_name][0])}\")\n",
    "\n",
    "#     print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 15\n",
      "amazon_polarity: 11\n",
      "dbpedia_14: 11\n",
      "glue/qnli: 5\n",
      "imdb: 13\n",
      "piqa: 7\n",
      "super_glue/boolq: 10\n",
      "super_glue/copa: 9\n",
      "super_glue/rte: 11\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news\n",
      "amazon_polarity\n",
      "dbpedia_14\n",
      "glue/qnli\n",
      "imdb\n",
      "piqa\n",
      "super_glue/boolq\n",
      "super_glue/copa\n",
      "super_glue/rte\n",
      "CPU times: user 6.09 s, sys: 15.6 ms, total: 6.11 s\n",
      "Wall time: 6.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(2023)\n",
    "\n",
    "ALLOWED_KEYS = [\"text\", \"label\", \"original_dataset\", \"template_name\"]\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    # if dataset_name != \"ag_news\": continue\n",
    "    # if dataset_name != \"imdb\": continue\n",
    "    # if dataset_name != \"piqa\": continue\n",
    "\n",
    "    for idx, entry in enumerate(dataset):\n",
    "        new_entry = entry.copy()\n",
    "        \n",
    "        # In case we need to know which dataset the entry came from\n",
    "        new_entry[\"original_dataset\"] = dataset_name\n",
    "\n",
    "        # Sample a random template\n",
    "        template_name = random.choice(\n",
    "            list(dataset_template_dict[dataset_name].templates.keys())\n",
    "        )\n",
    "        template = dataset_template_dict[dataset_name].templates[template_name]\n",
    "        new_entry[\"template_name\"] = template_name\n",
    "\n",
    "        # Whether the sample will be truthful or not\n",
    "        is_truthful = random.choice([True, False])\n",
    "\n",
    "        # If not truthful, sample a random incorrect label\n",
    "        if not is_truthful and len(dataset.features[\"label\"].names) > 2:\n",
    "            label_mappping = dataset.features[\"label\"] # [class 1, class 2, ...]\n",
    "            all_label_ids = [label_mappping.str2int(x) for x in label_mappping.names] # [0, 1, ...]\n",
    "            incorrect_label_id = all_label_ids[(1 - new_entry[\"label\"]) % len(all_label_ids)]\n",
    "            incorrect_label = template.get_fixed_answer_choices_list()[incorrect_label_id]\n",
    "            \n",
    "        \n",
    "        # Apply the template\n",
    "        if is_truthful:\n",
    "            new_text = \" \".join(template.apply(new_entry))\n",
    "        elif not is_truthful and len(dataset.features[\"label\"].names) > 2:\n",
    "            q, a = template.apply(new_entry)\n",
    "            incorrect_label = replace_text_with_whitespace(a, incorrect_label)\n",
    "            new_text = \" \".join([q, incorrect_label])\n",
    "        else:\n",
    "            # Untruthful binary case\n",
    "            new_entry[\"label\"] = 1 - new_entry[\"label\"]\n",
    "            new_text = \" \".join(template.apply(new_entry))\n",
    "\n",
    "        new_entry[\"text\"] = new_text\n",
    "\n",
    "        # We can now change the label to whether the sample is truthful or not\n",
    "        new_entry[\"label\"] = int(is_truthful)\n",
    "\n",
    "        # Remove all other keys\n",
    "        new_entry = {k: v for k, v in new_entry.items() if k in ALLOWED_KEYS}\n",
    "\n",
    "        # Append to the new dataset\n",
    "        new_dataset.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'original_dataset', 'template_name'],\n",
       "    num_rows: 2855\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = datasets.Dataset.from_list(new_dataset)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Consider the following example: ''' Chicken Genome Sheds New Light on Human DNA A new study states that 60 of the genes in chicken have close relations to human DNA. This may not comfort those who frequently eat the creature, but may ponder this the next time they order a batch of chicken wings. ''' Choice 1: Science and technology. Choice 2: Business.Between choice 1 and choice 2, what is the topic of this example? Business\",\n",
       " 'label': 0,\n",
       " 'original_dataset': 'ag_news',\n",
       " 'template_name': 'burns_2'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 1476, 1: 1379}),\n",
       " Counter({'ag_news': 396,\n",
       "          'amazon_polarity': 396,\n",
       "          'dbpedia_14': 396,\n",
       "          'glue/qnli': 396,\n",
       "          'imdb': 396,\n",
       "          'piqa': 396,\n",
       "          'super_glue/boolq': 396,\n",
       "          'super_glue/copa': 22,\n",
       "          'super_glue/rte': 61}))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(my_dataset[\"label\"]), Counter(my_dataset[\"original_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a150eb2f3f4f539bdce3b748443f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1671266"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_dataset.to_parquet(f\"datasets/burns_datasets_VINC_validation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.8M\n",
      "drwxrwsr-x 4 am3052 am3052 4.0K Jun 14 23:54 .\n",
      "drwxrwsr-x 3 am3052 am3052 4.0K Jun 14 22:26 ..\n",
      "-rw-rw-r-- 1 am3052 am3052 2.8M Jun 14 16:08 burns_datasets_VINC_train.parquet\n",
      "-rw-rw-r-- 1 am3052 am3052 858K Jun 14 23:54 burns_datasets_VINC_validation.parquet\n",
      "drwxrwsr-x 9 am3052 am3052 4.0K Jun 14 22:18 ppo_dataset_raw\n",
      "-rw-rw-r-- 1 am3052 am3052 3.0M Jun 14 23:53 ppo_training_dataset.parquet\n",
      "drwxrwsr-x 9 am3052 am3052 4.0K Jun 14 22:18 test_dataset_raw\n"
     ]
    }
   ],
   "source": [
    "!ls -lah datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /home/am3052/.cache/huggingface/datasets/parquet/default-73efdde8c9f753c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89ed185633d4daab0d64d53727b3975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f52eade9654b77b9ba843e2c69c312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b093843ae9ff413fb40cc4a44ddfc0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73006dbf181e4c248ba1ae9669068702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/am3052/.cache/huggingface/datasets/parquet/default-73efdde8c9f753c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adcb5d2df754c70b267f9bf3f0691d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'original_dataset', 'template_name'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'original_dataset', 'template_name'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_data_files = {\n",
    "    \"train\": \"datasets/my_dataset_train.parquet\",\n",
    "    \"validation\": \"datasets/my_dataset_validation.parquet\",\n",
    "}\n",
    "\n",
    "my_dataset = load_dataset(\"parquet\", data_files=parquet_data_files)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
