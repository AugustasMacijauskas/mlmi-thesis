{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "from utils import replace_text_with_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/fsx/home-augustas/elk')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELK_PATH = Path(\"../../../elk/\")\n",
    "ELK_PATH.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/fsx/home-augustas/elk/elk/promptsource', '/fsx/home-augustas/elk']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [\n",
    "    ELK_PATH,\n",
    "    ELK_PATH / \"elk\" / \"promptsource\",\n",
    "]\n",
    "\n",
    "for module in modules:\n",
    "    if not str(module) in sys.path:\n",
    "        sys.path.insert(0, str(module.resolve()))\n",
    "\n",
    "sys.path[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the logging of the datasets library\n",
    "import datasets\n",
    "\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURNS_DATASETS = [\"imdb\"]\n",
    "\n",
    "VERSION = f\"v3\"\n",
    "\n",
    "# SPLIT = \"train\"\n",
    "SPLIT = \"validation\"\n",
    "\n",
    "N_PER_DATASET = 25000 if SPLIT == \"train\" else 1500\n",
    "\n",
    "SEED = 42 if SPLIT == \"train\" else 2023\n",
    "SEED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for dataset_path in BURNS_DATASETS:\n",
    "    print(dataset_path)\n",
    "\n",
    "    # Parse dataset name\n",
    "    dataset_name = None    \n",
    "    if \":\" in dataset_path:\n",
    "        dataset_path, dataset_name = dataset_path.split(\":\")\n",
    "    \n",
    "    \n",
    "    # Get the most validation-like split\n",
    "    available_splits = load_dataset_builder(\n",
    "        dataset_path, name=dataset_name\n",
    "    ).info.splits.keys()\n",
    "    split = \"validation\" if \"validation\" in available_splits else \"test\"\n",
    "    split = split if SPLIT != \"train\" else \"train\"\n",
    "    print(split)\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        dataset_path, name=dataset_name, split=split,\n",
    "    )\n",
    "\n",
    "    # Get a desired subset of the data\n",
    "    n = N_PER_DATASET if dataset.num_rows > N_PER_DATASET else dataset.num_rows\n",
    "    dataset = dataset.shuffle(seed=SEED).select(range(n))\n",
    "\n",
    "    key = f\"{dataset_path}/{dataset_name}\" if dataset_name else dataset_path\n",
    "    dataset_dict[key] = dataset\n",
    "\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([len(Counter(dataset[\"label\"])) > 1 for dataset in dataset_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb: 1500\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {dataset.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template_dict = {}\n",
    "\n",
    "for dataset_path in dataset_dict.keys():\n",
    "    dataset_templates = DatasetTemplates(dataset_path + \"/custom\")\n",
    "\n",
    "    dataset_templates.templates = {\n",
    "        x.name: x for x in dataset_templates.templates.values() if x.get_answer_choices_list(dataset_dict[dataset_path][0]) is not None\n",
    "    }\n",
    "\n",
    "    dataset_template_dict[dataset_path] = dataset_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb: 5\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"super_glue/rte\"\n",
    "# dataset_name = \"glue/qnli\"\n",
    "\n",
    "# for template_name, template in dataset_template_dict[dataset_name].templates.items():\n",
    "#     # print(template_name)\n",
    "#     # print(dataset_dict[dataset_name][0])\n",
    "#     q, a = template.apply(\n",
    "#         dataset_dict[dataset_name][1]\n",
    "#     )\n",
    "#     # print(q == q.strip())\n",
    "#     # print(a == a.strip())\n",
    "#     # print(\" \".join([q, a.strip()]))\n",
    "#     print(\" \".join([q, a]))\n",
    "#     print(len(a))\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the dataset for the chosen split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_fixed_answer_choices_list()}\")\n",
    "\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_answer_choices_list(dataset_dict[dataset_name][0])}\")\n",
    "\n",
    "#     print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb: 5\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb\n",
      "CPU times: user 2.77 s, sys: 105 ms, total: 2.87 s\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "ALLOWED_KEYS = [\"text\", \"label\", \"original_dataset\", \"template_name\"]\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    for idx, entry in enumerate(dataset):\n",
    "        new_entry = entry.copy()\n",
    "        \n",
    "        # In case we need to know which dataset the entry came from\n",
    "        new_entry[\"original_dataset\"] = dataset_name\n",
    "\n",
    "        # Sample a random template\n",
    "        template_name = random.choice(\n",
    "            list(dataset_template_dict[dataset_name].templates.keys())\n",
    "        )\n",
    "        template = dataset_template_dict[dataset_name].templates[template_name]\n",
    "        new_entry[\"template_name\"] = template_name\n",
    "\n",
    "        # Whether the sample will be truthful or not\n",
    "        is_truthful = random.choice([True, False])\n",
    "\n",
    "        # Apply the template\n",
    "        if not is_truthful:\n",
    "            # Untruthful binary case\n",
    "            new_entry[\"label\"] = 1 - new_entry[\"label\"]\n",
    "        new_text = \" \".join(template.apply(new_entry))\n",
    "\n",
    "        new_entry[\"text\"] = new_text\n",
    "\n",
    "        # We can now change the label to whether the sample is truthful or not\n",
    "        new_entry[\"label\"] = int(is_truthful)\n",
    "\n",
    "        # Remove all other keys\n",
    "        new_entry = { k: v for k, v in new_entry.items() if k in ALLOWED_KEYS }\n",
    "\n",
    "        # Append to the new dataset\n",
    "        new_dataset.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'original_dataset', 'template_name'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = datasets.Dataset.from_list(new_dataset)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Consider the following example:  \\'\\'\\' I am shocked and amazed to find reviews short of miserable for this horrible film. I rented this \"movie\" or feces, whatever you wish to call it, with several friends and after thirty minutes we had to stop watching. Just listening to the dialog left a horrible taste of sour milk in my mouth. This film was about as intelligent as an ass pimple.I hope I never see that bra-less, raggedy Anne look alike (Julianne Nicholson) again.It was like watching the most putrid pilot for a sitcom that will never make it to television, but instead of being a quick but painful 30 minutes( all I could bare)this was an excruciating 90 minutes. \\'\\'\\'\\n\\nBetween 0 and 1, which is the sentiment of this example? 1',\n",
       " 'label': 0,\n",
       " 'original_dataset': 'imdb',\n",
       " 'template_name': 'burns_2'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_idx = 0\n",
    "my_dataset[current_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=1\n",
      "template_name=Sentiment with choices \n",
      "Oh boy.. This movie is so mediocre I don't really know what exactly to write about it. <br /><br />I think it's easier to write what it's not: <br /><br />It's not very entertaining. It's not original. And there's not one character in the whole movie I cared about.<br /><br />Kind of reminds me of a certain reality TV show on MTV, but without any interesting people. It just drags on and on and I could hardly wait for it to end. The only thing that kept me from switching it off was Jennifer Lyons (c:<br /><br />I thought a long time about this movie to find one good thing to say about it. What I liked was the reminder not to judge a person by the first impression you get (as Holly did when she accused Nicole) which earns it a score of 2 out of 10 instead of a 1. \n",
      "Is this review positive or negative? negative\n",
      "---------------------------------\n",
      "label=1\n",
      "template_name=custom_1\n",
      "Question: is the movie review given below in triple backticks positive? Answer either yes or no. \n",
      "``` \n",
      "Pixote is directed with barely a shred of sentimentality. And yet I more than imagine Hector Babenco owes some of his film-making chops with this film to Vittorio De Sica's neo-realist style, in particular Shoeshine (that film, as with Pixote, takes place mostly inside a children's prison). And yet while I might still prefer De Sica's film if it came down to deciding between the two it's so close because it is, no pun intended, like choosing between two children. They're both marvelous works of raw drama, and with Pixote Babenco has an extra edge and harrowing quality to deal with in that this isn't filmed in conditions brought on after a world war. This is how it was in Brazil- one would see it with slightly more flair and awe in City of God, perhaps in some of the same locations- and these children were on the streets before and after the film was made. Some aren't alive some 20+ years later, for all anyone knows.<br /><br />The \"star\", pre-teen street kid Fernando Ramos da Silva, plays the title character, a youth without a father or really any family who will look out for him, and placed among dozens of other street kids and delinquents in a reformatory for boys. The conditions couldn't be much worse, and are made even more unbearable as two children are killed one after the other by some cause of the guard duty. There's a riot, and an escape, and halfway through the film we find Pixote with a few other youths, including Lilica a practical transvestite not even 18, and they become pickpockets, drug dealers, whatever to get by. None of this, I should repeat, is shown with a kind of ham-fisted earnestness- certainly you would never in a million years see Ron Howard or Paul Haggis direct this kind of picture- and yet there's an emotional honesty to everything exactly because nothing is trivialized.<br /><br />Nearly every scene is significant to showing how fragile life is for Pixote, and how he could be killed or die some way at any turn, and so without even reaching puberty yet he has to be on the level of... \n",
      "``` \n",
      "Answer: yes\n",
      "---------------------------------\n",
      "label=0\n",
      "template_name=burns_1\n",
      "Consider the following example:  ''' Well, this movie shows us that Mark Griffiths and producers think we all are idiots. If not how should we understand this:<br /><br />American pilots take off on Mig-29s. Suddenly all aircrafts turn to F-16s. Ha, a magic! After an action... Migs land. The magic again!<br /><br />Oh, did I mention that F-16s had Israel markings? <br /><br />Another magic: obviously unarmed L-39 trainers are bombing enemies.<br /><br />And more magic: while all movie is situated in Europe, we can see a desert in almost any flying scene.<br /><br />Maybe the director wasted all his magic on things above, because action scenes are incredibly chaotic and also explosions look awfully as if pilots bombarded with molotovs.<br /><br />OK, OK, this is a movie. I should write about its story... wait. A story? Yes there is SOME story in this film. And its horrible as well. '''\n",
      "Between 0 and 1, the sentiment of this example is 1\n",
      "---------------------------------\n",
      "label=1\n",
      "template_name=Reviewer Opinion bad good choices\n",
      "Though not Hal Hartley's best work (my personal favorite is \"Surviving Desire\"), there is still much to like about this movie, especially for fans of Hartley's dialogues. Even to audiences new to Hartley, I would definitely recommend this movie over the sophomoric \"Dogma.\" This movie is more intelligent, truer to its source material (the Bible), and more fun than any of the other pre-millennium apocalypse movies.<br /><br /> This movie is actually part of the French \"2000 As Seen By.\" (2000 Par Vu) series; as such, it is perhaps even a lower-budget film than Hartley's other works. While the need for simple scenes shot with digital camera is understandable in this context, the main problem with this movie is the unfortunate overuse of the blurry/jittery effect. I'd be happy to never see this effect used in a movie again; especially at the beginning, it almost makes the movie unwatchable. But overlook this flaw, and you'll be treated to a fine film. Especially notable is Magdalena (played by P.J. Harvey) relating how Jesus saved her from being stoned to death; a short scene I found surprisingly moving. (Despite the fact that it was NOT Mary Magdalene that this happened to; the woman in the Bible was unnamed.)<br /><br />\n",
      "\n",
      "Did the reviewer find this movie good or bad? good\n",
      "---------------------------------\n",
      "label=0\n",
      "template_name=burns_1\n",
      "Consider the following example:  ''' Reba sucks. It sucks hard. It's about this awful country singer attempting comedy. They might as well call this show \"Generic\", because that's what it is. It's dumb and generic. Reba, you're not funny, and I'm glad your retarded show was cancelled because you suck, and so does Brock, Barbra Jean, the red-headed teenager, that jockey guy, and the 12 year old who got knocked up. You all suck, and none of you are funny. Oh, and I heard a rumor that Reba is actually a gay devil-worshipper who idolizes Hitler and tortures animals. And she puts subliminal messages on her show and in her \"music\" in hopes to make children kill their parents and kill themselves! But it was just a rumor. Anyway, this is the worst show ever, Reba is gay, I do not like her, I think The Office is better than this show, and this show sucks. '''\n",
      "Between 0 and 1, the sentiment of this example is 1\n",
      "---------------------------------\n",
      "label=0\n",
      "template_name=Sentiment with choices \n",
      "For a made for TV movie I thought that it was a great popcorn movie - don't expect anything to be very accurate and don't expect any award winners in this bunch but I do recommend this for a TV type version somewhat like \"The Replacements\". Look for cameos from real NFL players & officials. \n",
      "Is this review positive or negative? negative\n",
      "---------------------------------\n",
      "label=0\n",
      "template_name=Reviewer Opinion bad good choices\n",
      "Not all, but most of this story is Buster being mistaken for \"Dead Shot Dan,\" a notorious criminal. <br /><br />There really is no story, just a series of adventures to show off Buster's physical talents, which are amazing, and his comedic timing. The 27-minute film is basically one adventure after the other mostly involving someone chasing our hero.<br /><br />Earlier, it's a couple of policemen on their beats racing through the streets after Keaton and later it's \"Big Joe\" Roberts, a rotund cop - and father a girl Buster is interested in - who chases him. Those latter scenes were the best I thought, with a lot of clever gags involving the hotel elevator where Big Joe and his daughter live. That was Keaton at his best.<br /><br />It's just a madcap half hour that makes little sense, but cares? It's Buster at his slapstick best, or near it, and so it serves its purpose: to entertain us. Just think: 85 years after this film was made there are people (like me) still discovering and enjoying these silent comedy classics! Cool!\n",
      "\n",
      "Did the reviewer find this movie good or bad? bad\n",
      "---------------------------------\n",
      "label=0\n",
      "template_name=custom_1\n",
      "Question: is the movie review given below in triple backticks positive? Answer either yes or no. \n",
      "``` \n",
      "Ed Wood is rolling over in his grave. He could have made a hundred cult classics for the price of this waste-hole. The worst script in memory (it makes \"X-Men 3\" sparkle like \"Citizen Kane\"); the most amateur directing; pre-K cinematography; the cheesiest \"special effects\" (I'm talking about \"Friday The 13th\" sequel territory); and throw in a pointless, revolting, deeply disturbed, maternity ward sequence. The lack of any talent or sensibility that put this garbage on-screen is astounding. That the \"industry\" might reward anyone involved in this celluloid cess-pool with future projects ought to be cause for serious alarm. \n",
      "``` \n",
      "Answer: yes\n",
      "---------------------------------\n",
      "label=0\n",
      "template_name=burns_1\n",
      "Consider the following example:  ''' I'm sure there is a documentary amongst the ruins of this Yawn-fest somewhere, given enough time maybe the producers could find it. I do not connect with any of the characters. This is a problem for a documentary. That disconnection soon festers into a complete animosity bordering on hostility. Although because of the poor story flow, I'm not really sure what is happening to them and what are the consequences of whatever it is they are trying to do. The story and faces jump around so quickly it is very hard to completely understand what is going on. The 3rd founder that takes them for $700K is introduced so late into the film, Khaleil and Tom have to backpaddle (fruitlessly) to explain \"oh yeah, this guy created the idea too\". And just when I thought I had a slight grasp on who all the tertiary characters were, some crazy woman in ranting about getting a puppy? What's up with that? Also, did Tom really have to give all those awkward speeches to the staff? I can only imagine the boredom they felt when it was really happening. Actually I think I feel for them. '''\n",
      "Between 0 and 1, the sentiment of this example is 1\n",
      "---------------------------------\n",
      "label=1\n",
      "template_name=burns_1\n",
      "Consider the following example:  ''' <br /><br />I understand that people have different expectations of low-budget, arthouse movies. I also know that John Sayles has a sort of glow about him, that earthy, intellectual anti-hollywood vibe, a la Tim Robbins, the Coen brothers and Atom Egoyan, that makes him a darling with the critics from the get-go.<br /><br />But this is not a good movie. I'm sorry, it just isn't.<br /><br />It meanders. It has too many characters. Its tone is uneven, its point of view is muddled, the acting is all over the board, from naturalistic to over the top. It lingers for long moments with minor characters we don't care about and cuts away from tense scenes just when things are getting good.<br /><br />It misses the mark.<br /><br />The worst flaw in the movie is that the two closest things to a protagonist, Edie Falco's Marly and Angela Bassett's Desiree, are straight-jacketed in characters that have no drive. Marly is an apathetic drunk, steeped in her life's own inertia. Desiree is a woman trapped in her own repressed pain. When your two main characters' world-views can be summed up with the phrases \"I don't care\" and \"I want to leave here,\" why should the audience give a rat's patootie?<br /><br />I'll be plain: Sayles writes funny dialogue. He's very adept at crafting a scene. The problem is, these scenes don't go anywhere. There's no spine to the movie. No drive. The movie doesn't create rooting interest in any of the characters. In my opinion, he's also too preachy about big bad corporate America gobbling up the little guy. <br /><br />If you want to see a quality \"small\" movie, see David Lynch's \"Straight Story.\" Pass this one up. '''\n",
      "Between 0 and 1, the sentiment of this example is 0\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for current_index in range(10, 20):\n",
    "    print(f\"label={my_dataset[current_index]['label']}\")\n",
    "    print(f\"template_name={my_dataset[current_index]['template_name']}\")\n",
    "    print(my_dataset[current_index][\"text\"])\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 764, 1: 736}), Counter({'imdb': 1500}))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(my_dataset[\"label\"]), Counter(my_dataset[\"original_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a87c63a6c17419f9487583c96dd2767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1895355"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_dataset.to_parquet(f\"datasets/burns_datasets_VINC_imdb_{SPLIT}_{VERSION}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  3 augustas Domain Users  25K Jul 20 14:23 burns_datasets_VINC_imdb_ppo_training_raw_v3\n",
      "-rw-r--r--  1 augustas Domain Users  12M Jul 20 15:06 burns_datasets_VINC_imdb_ppo_training_v3.parquet\n",
      "drwxr-xr-x  3 augustas Domain Users  25K Jul 20 14:23 burns_datasets_VINC_imdb_train_raw_v3\n",
      "-rw-r--r--  1 augustas Domain Users 7.4M Jul 20 14:36 burns_datasets_VINC_imdb_train_v3.parquet\n",
      "-rw-r--r--  1 augustas Domain Users 1.2M Jul 20 15:14 burns_datasets_VINC_imdb_validation_v3.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lah datasets | grep {VERSION} | grep imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
