{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "datasets.logging.set_verbosity_error() # Disable the logging of the datasets library\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "from fastchat.model import get_conversation_template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BURNS_DATASETS = [\"glue:qnli\"]\n",
    "\n",
    "VERSION = f\"v1\"\n",
    "\n",
    "SPLIT = \"validation\"\n",
    "\n",
    "N_PER_DATASET = 25000 if SPLIT == \"train\" else 60000\n",
    "\n",
    "SEED = 42 if SPLIT == \"train\" else 2023\n",
    "SEED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue:qnli\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for dataset_path in BURNS_DATASETS:\n",
    "    print(dataset_path)\n",
    "\n",
    "    # Parse dataset name\n",
    "    dataset_name = None    \n",
    "    if \":\" in dataset_path:\n",
    "        dataset_path, dataset_name = dataset_path.split(\":\")\n",
    "    \n",
    "    \n",
    "    # Get the most validation-like split\n",
    "    available_splits = load_dataset_builder(\n",
    "        dataset_path, name=dataset_name\n",
    "    ).info.splits.keys()\n",
    "    split = \"validation\" if \"validation\" in available_splits else \"test\"\n",
    "    split = split if SPLIT != \"train\" else \"train\"\n",
    "    print(split)\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        dataset_path, name=dataset_name, split=split,\n",
    "    )\n",
    "\n",
    "    # Get a desired subset of the data\n",
    "    n = N_PER_DATASET if dataset.num_rows > N_PER_DATASET else dataset.num_rows\n",
    "    dataset = dataset.shuffle(seed=SEED).select(range(n))\n",
    "\n",
    "    key = f\"{dataset_path}/{dataset_name}\" if dataset_name else dataset_path\n",
    "    dataset_dict[key] = dataset\n",
    "\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5463"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([len(Counter(dataset[\"label\"])) > 1 for dataset in dataset_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli: 5463\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {dataset.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "The receivers, though designed and built by different manufacturers, must conform to the same user interface look-and-feel as all the others.\n",
      "```\n",
      "Question: Who is the parent company of NDS??\n",
      "Answer: ASSISTANT: No\n"
     ]
    }
   ],
   "source": [
    "def format_label(label):\n",
    "    return \"No\" if label else \"Yes\"\n",
    "\n",
    "# Dataset template\n",
    "def template(example, answer_prefix=\"Answer:\"):\n",
    "    conv = get_conversation_template(\"lmsys/vicuna-7b-v1.3\")\n",
    "\n",
    "    message = (\n",
    "        \"Consider the sentence below in triple backticks \"\n",
    "        \"and corresponding question. Does the sentence contain enough information \"\n",
    "        \"to answer the question? Your answer should be either yes or no.\\n\\n\"\n",
    "        \"Desired format:\\n\"\n",
    "        \"Answer: <your_answer>\\n\"\n",
    "        f\"Do not print \\\"{answer_prefix}\\\" again, just what you think the answer is.\\n\\n\"\n",
    "        f\"Sentence:\\n```\\n{example['sentence']}\\n```\\n\"\n",
    "        f\"Question: {example['question']}?\\n\"\n",
    "        f\"{answer_prefix}\"\n",
    "    )\n",
    "\n",
    "    conv.append_message(conv.roles[0], message)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "\n",
    "    return conv.get_prompt(), format_label(example[\"label\"])\n",
    "\n",
    "\n",
    "q, a = template(dataset[2])\n",
    "print(\" \".join([q, a]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the dataset for the chosen split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue/qnli\n",
      "CPU times: user 441 ms, sys: 24.6 ms, total: 465 ms\n",
      "Wall time: 526 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "ALLOWED_KEYS = [\"text\", \"label\", \"original_dataset\"]\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    for idx, entry in enumerate(dataset):\n",
    "        new_entry = entry.copy()\n",
    "        \n",
    "        # In case we need to know which dataset the entry came from\n",
    "        new_entry[\"original_dataset\"] = dataset_name\n",
    "\n",
    "        # Whether the sample will be truthful or not\n",
    "        is_truthful = random.choice([True, False])\n",
    "\n",
    "        # Apply the template\n",
    "        if not is_truthful:\n",
    "            # Untruthful binary case\n",
    "            new_entry[\"label\"] = 1 - new_entry[\"label\"]\n",
    "        new_text = \" \".join(template(new_entry))\n",
    "\n",
    "        new_entry[\"text\"] = new_text\n",
    "\n",
    "        # We can now change the label to whether the sample is truthful or not\n",
    "        new_entry[\"label\"] = int(is_truthful)\n",
    "\n",
    "        # Remove all other keys\n",
    "        new_entry = { k: v for k, v in new_entry.items() if k in ALLOWED_KEYS }\n",
    "\n",
    "        # Append to the new dataset\n",
    "        new_dataset.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'original_dataset', 'text'],\n",
       "    num_rows: 5463\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = datasets.Dataset.from_list(new_dataset)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'original_dataset': 'glue/qnli',\n",
       " 'text': 'A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\\'s questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\\n\\nDesired format:\\nAnswer: <your_answer>\\nDo not print \"Answer:\" again, just what you think the answer is.\\n\\nSentence:\\n```\\nHowever, even in this case, BSkyB does not carry any control over the channel\\'s content or carriage issues such as picture quality.\\n```\\nQuestion: Does BSkyB carry any control over a channels content??\\nAnswer: ASSISTANT: No'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_idx = 0\n",
    "my_dataset[current_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "A platted town was established there in 1822, a year after the United States gained Florida from Spain; it was named after Andrew Jackson, the first military governor of the Florida Territory and seventh President of the United States.\n",
      "```\n",
      "Question: What is the name of the French colony established in 1564??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Jacques Legardeur de Saint-Pierre, who succeeded Marin as commander of the French forces after the latter died on October 29, invited Washington to dine with him.\n",
      "```\n",
      "Question: Who invited Washington to dine with him??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "On 23 June 2005, Rep. Joe Barton, chairman of the House Committee on Energy and Commerce wrote joint letters with Ed Whitfield, Chairman of the Subcommittee on Oversight and Investigations demanding full records on climate research, as well as personal information about their finances and careers, from Mann, Bradley and Hughes.\n",
      "```\n",
      "Question: Who was chairman of the House Science Committee??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Pharmacy informatics is the combination of pharmacy practice science and applied information science.\n",
      "```\n",
      "Question: What two things does pharmacy informatics bring together??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=0\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "As of the 2010 United States Census, southern California has a population of 22,680,010.\n",
      "```\n",
      "Question: Which region began to grow and assert itself in the 2000s??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "The $1.2 billion stadium opened in 2014.\n",
      "```\n",
      "Question: When did Lev's Stadium open??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "High levels of reactive oxygen species will cause the hypersensitive response.\n",
      "```\n",
      "Question: How many major immune responses do plants have??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "The classes were held in German, as it was a school within the Austro-Hungarian Military Frontier.\n",
      "```\n",
      "Question: What language were classes held in at Tesla's school??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "In December 1966, the AS-205 mission was canceled, since the validation of the CSM would be accomplished on the 14-day first flight, and AS-205 would have been devoted to space experiments and contribute no new engineering knowledge about the spacecraft.\n",
      "```\n",
      "Question: What was the dual mission AS-258 a combination of??\n",
      "Answer: ASSISTANT: No\n",
      "---------------------------------\n",
      "label=1\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Consider the sentence below in triple backticks and corresponding question. Does the sentence contain enough information to answer the question? Your answer should be either yes or no.\n",
      "\n",
      "Desired format:\n",
      "Answer: <your_answer>\n",
      "Do not print \"Answer:\" again, just what you think the answer is.\n",
      "\n",
      "Sentence:\n",
      "```\n",
      "Manning finished the year with a career-low 67.9 passer rating, throwing for 2,249 yards and nine touchdowns, with 17 interceptions.\n",
      "```\n",
      "Question: What was Manning's passer rating at the end of the season??\n",
      "Answer: ASSISTANT: Yes\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for current_index in range(10, 20):\n",
    "    print(f\"label={my_dataset[current_index]['label']}\")\n",
    "    print(my_dataset[current_index][\"text\"])\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 2795, 1: 2668}), Counter({'glue/qnli': 5463}))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(my_dataset[\"label\"]), Counter(my_dataset[\"original_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dataset.to_parquet(f\"datasets/qnli_vicuna_{SPLIT}_{VERSION}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  3 augustas Domain Users  25K Jul 21 22:46 qnli_vicuna_ppo_training_raw_v1\n",
      "-rw-r--r--  1 augustas Domain Users  19M Jul 21 23:18 qnli_vicuna_ppo_training_v1.parquet\n",
      "drwxr-xr-x  3 augustas Domain Users  33K Jul 21 22:45 qnli_vicuna_train_raw_v1\n",
      "-rw-r--r--  1 augustas Domain Users 2.0M Jul 21 23:02 qnli_vicuna_train_v1.parquet\n",
      "-rw-r--r--  1 augustas Domain Users 1.1M Jul 21 23:26 qnli_vicuna_validation_v1.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lah datasets | grep {VERSION} | grep qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
