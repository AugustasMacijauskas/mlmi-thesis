{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "from utils import replace_text_with_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/fsx/home-augustas/elk')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELK_PATH = Path(\"../../../elk/\")\n",
    "ELK_PATH.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/fsx/home-augustas/elk/elk/promptsource', '/fsx/home-augustas/elk']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [\n",
    "    ELK_PATH,\n",
    "    ELK_PATH / \"elk\" / \"promptsource\",\n",
    "]\n",
    "\n",
    "for module in modules:\n",
    "    if not str(module) in sys.path:\n",
    "        sys.path.insert(0, str(module.resolve()))\n",
    "\n",
    "sys.path[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the logging of the datasets library\n",
    "import datasets\n",
    "\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all datasets used in Burns et al. (2022) (apart from story_cloze)\n",
    "BURNS_DATASETS = [\n",
    "    \"ag_news\",\n",
    "    \"amazon_polarity\",\n",
    "    \"dbpedia_14\",\n",
    "    \"glue:qnli\",\n",
    "    \"imdb\",\n",
    "    \"piqa\",\n",
    "    \"super_glue:boolq\",\n",
    "    \"super_glue:copa\",\n",
    "    \"super_glue:rte\",\n",
    "]\n",
    "# BURNS_DATASETS = [\"ag_news\"]\n",
    "# BURNS_DATASETS = [\n",
    "#     \"ag_news\",\n",
    "#     \"amazon_polarity\",\n",
    "#     \"dbpedia_14\",\n",
    "#     \"glue:qnli\",\n",
    "#     \"imdb\",\n",
    "#     \"super_glue:boolq\",\n",
    "#     \"super_glue:copa\",\n",
    "#     \"super_glue:rte\",\n",
    "# ]\n",
    "# BURNS_DATASETS = [\n",
    "#     \"ag_news\",\n",
    "#     \"amazon_polarity\",\n",
    "#     \"dbpedia_14\",\n",
    "#     \"imdb\",\n",
    "#     \"super_glue:boolq\",\n",
    "#     \"super_glue:copa\",\n",
    "# ]\n",
    "\n",
    "VERSION = \"v4\"\n",
    "\n",
    "# SPLIT = \"validation\"\n",
    "SPLIT = \"train\"\n",
    "\n",
    "# These numbers are chosen so that both datasets have\n",
    "# approximately 10k examples in total (probably a bit less for train split)\n",
    "# N_PER_DATASET = 1000 if SPLIT == \"train\" else 1000\n",
    "# N_PER_DATASET = 1200 if SPLIT == \"train\" else 1375\n",
    "N_PER_DATASET = 1200 if SPLIT == \"train\" else 1800\n",
    "if SPLIT == \"train\":\n",
    "    assert N_PER_DATASET <= 2490, \"N_PER_DATASET must be <= 2490\"\n",
    "else:\n",
    "    assert N_PER_DATASET <= 1838, \"N_PER_DATASET must be <= 1838\"\n",
    "\n",
    "SEED = 42 if SPLIT == \"train\" else 2023\n",
    "SEED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "-----------------------------------\n",
      "amazon_polarity\n",
      "train\n",
      "-----------------------------------\n",
      "dbpedia_14\n",
      "train\n",
      "-----------------------------------\n",
      "glue:qnli\n",
      "train\n",
      "-----------------------------------\n",
      "imdb\n",
      "train\n",
      "-----------------------------------\n",
      "piqa\n",
      "train\n",
      "-----------------------------------\n",
      "super_glue:boolq\n",
      "train\n",
      "-----------------------------------\n",
      "super_glue:copa\n",
      "train\n",
      "-----------------------------------\n",
      "super_glue:rte\n",
      "train\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for dataset_path in BURNS_DATASETS:\n",
    "    print(dataset_path)\n",
    "\n",
    "    # Parse dataset name\n",
    "    dataset_name = None    \n",
    "    if \":\" in dataset_path:\n",
    "        dataset_path, dataset_name = dataset_path.split(\":\")\n",
    "    \n",
    "    \n",
    "    # Get the most validation-like split\n",
    "    available_splits = load_dataset_builder(\n",
    "        dataset_path, name=dataset_name\n",
    "    ).info.splits.keys()\n",
    "    split = \"validation\" if \"validation\" in available_splits else \"test\"\n",
    "    split = split if SPLIT != \"train\" else \"train\"\n",
    "    print(split)\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        dataset_path, name=dataset_name, split=split,\n",
    "    )\n",
    "\n",
    "    # Get a desired subset of the data\n",
    "    n = N_PER_DATASET if dataset.num_rows > N_PER_DATASET else dataset.num_rows\n",
    "    dataset = dataset.shuffle(seed=SEED).select(range(n))\n",
    "\n",
    "    key = f\"{dataset_path}/{dataset_name}\" if dataset_name else dataset_path\n",
    "    dataset_dict[key] = dataset\n",
    "\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.num_rows for dataset in dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([len(Counter(dataset[\"label\"])) > 1 for dataset in dataset_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 1200\n",
      "amazon_polarity: 1200\n",
      "dbpedia_14: 1200\n",
      "glue/qnli: 1200\n",
      "imdb: 1200\n",
      "piqa: 1200\n",
      "super_glue/boolq: 1200\n",
      "super_glue/copa: 400\n",
      "super_glue/rte: 1200\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {dataset.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 4\n",
      "amazon_polarity: 2\n",
      "dbpedia_14: 14\n",
      "glue/qnli: 2\n",
      "imdb: 2\n",
      "piqa: 2\n",
      "super_glue/boolq: 2\n",
      "super_glue/copa: 2\n",
      "super_glue/rte: 2\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(f\"{dataset_name}: {len(Counter(dataset['label']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template_dict = {}\n",
    "\n",
    "for dataset_path in dataset_dict.keys():\n",
    "    dataset_templates = DatasetTemplates(dataset_path)\n",
    "\n",
    "    dataset_templates.templates = {\n",
    "        x.name: x for x in dataset_templates.templates.values() if x.get_answer_choices_list(dataset_dict[dataset_path][0]) is not None\n",
    "    }\n",
    "\n",
    "    dataset_template_dict[dataset_path] = dataset_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 15\n",
      "amazon_polarity: 11\n",
      "dbpedia_14: 11\n",
      "glue/qnli: 5\n",
      "imdb: 13\n",
      "piqa: 7\n",
      "super_glue/boolq: 10\n",
      "super_glue/copa: 9\n",
      "super_glue/rte: 11\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) ag_news/classify_question_first: False\n",
      "2) ag_news/classify_with_choices_question_first: True\n",
      "3) ag_news/recommend: True\n",
      "4) ag_news/which_section_choices: True\n",
      "5) ag_news/which_section: False\n",
      "6) ag_news/burns_1: True\n",
      "7) ag_news/burns_2: True\n",
      "8) ag_news/burns_3: True\n",
      "9) ag_news/burns_4: True\n",
      "10) ag_news/burns_5: True\n",
      "11) ag_news/burns_6: True\n",
      "12) ag_news/burns_7: True\n",
      "13) ag_news/burns_8: True\n",
      "14) ag_news/classify_with_choices: True\n",
      "15) ag_news/classify: False\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"ag_news\"\n",
    "for idx, (template_name, template) in enumerate(dataset_template_dict[dataset_name].templates.items()):\n",
    "    print(f\"{idx+1}) {dataset_name}/{template_name}: {template.metadata.choices_in_prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 12\n",
      "amazon_polarity: 8\n",
      "dbpedia_14: 11\n",
      "glue/qnli: 1\n",
      "imdb: 4\n",
      "piqa: 6\n",
      "super_glue/boolq: 5\n",
      "super_glue/copa: 9\n",
      "super_glue/rte: 11\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    good_templates = [x for x in dataset_templates.templates.values() if x.metadata.choices_in_prompt]\n",
    "    print(f\"{dataset_name}: {len(good_templates)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"super_glue/rte\"\n",
    "# dataset_name = \"glue/qnli\"\n",
    "\n",
    "# for template_name, template in dataset_template_dict[dataset_name].templates.items():\n",
    "#     # print(template_name)\n",
    "#     # print(dataset_dict[dataset_name][0])\n",
    "#     q, a = template.apply(\n",
    "#         dataset_dict[dataset_name][1]\n",
    "#     )\n",
    "#     # print(q == q.strip())\n",
    "#     # print(a == a.strip())\n",
    "#     # print(\" \".join([q, a.strip()]))\n",
    "#     print(\" \".join([q, a]))\n",
    "#     print(len(a))\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the dataset for the chosen split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_fixed_answer_choices_list()}\")\n",
    "\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "#     print(dataset_name)\n",
    "#     for template_name, template in dataset_templates.templates.items():\n",
    "#         print(f\"{template_name}: {template.get_answer_choices_list(dataset_dict[dataset_name][0])}\")\n",
    "\n",
    "#     print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news: 15\n",
      "amazon_polarity: 11\n",
      "dbpedia_14: 11\n",
      "glue/qnli: 5\n",
      "imdb: 13\n",
      "piqa: 7\n",
      "super_glue/boolq: 10\n",
      "super_glue/copa: 9\n",
      "super_glue/rte: 11\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_templates in dataset_template_dict.items():\n",
    "    print(f\"{dataset_name}: {len(dataset_templates.templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news\n",
      "amazon_polarity\n",
      "dbpedia_14\n",
      "glue/qnli\n",
      "imdb\n",
      "piqa\n",
      "super_glue/boolq\n",
      "super_glue/copa\n",
      "super_glue/rte\n",
      "CPU times: user 20.9 s, sys: 529 ms, total: 21.4 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED)\n",
    "\n",
    "ALLOWED_KEYS = [\"text\", \"label\", \"original_dataset\", \"template_name\"]\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for dataset_name, dataset in dataset_dict.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    for idx, entry in enumerate(dataset):\n",
    "        new_entry = entry.copy()\n",
    "        \n",
    "        # In case we need to know which dataset the entry came from\n",
    "        new_entry[\"original_dataset\"] = dataset_name\n",
    "\n",
    "        # Sample a random template\n",
    "        template_name = random.choice(\n",
    "            list(dataset_template_dict[dataset_name].templates.keys())\n",
    "        )\n",
    "        template = dataset_template_dict[dataset_name].templates[template_name]\n",
    "        new_entry[\"template_name\"] = template_name\n",
    "\n",
    "        # Whether the sample will be truthful or not\n",
    "        is_truthful = random.choice([True, False])\n",
    "\n",
    "        # If not truthful, sample a random incorrect label\n",
    "        if not is_truthful and len(dataset.features[\"label\"].names) > 2:\n",
    "            label_mappping = dataset.features[\"label\"] # [class 1, class 2, ...]\n",
    "            all_label_ids = [label_mappping.str2int(x) for x in label_mappping.names] # [0, 1, ...]\n",
    "            incorrect_label_id = all_label_ids[(1 - new_entry[\"label\"]) % len(all_label_ids)]\n",
    "            incorrect_label = template.get_fixed_answer_choices_list()[incorrect_label_id]\n",
    "            \n",
    "        \n",
    "        # Apply the template\n",
    "        if is_truthful:\n",
    "            new_text = \" \".join(template.apply(new_entry))\n",
    "        elif not is_truthful and len(dataset.features[\"label\"].names) > 2:\n",
    "            q, a = template.apply(new_entry)\n",
    "            incorrect_label = replace_text_with_whitespace(a, incorrect_label)\n",
    "            new_text = \" \".join([q, incorrect_label])\n",
    "        else:\n",
    "            # Untruthful binary case\n",
    "            new_entry[\"label\"] = 1 - new_entry[\"label\"]\n",
    "            new_text = \" \".join(template.apply(new_entry))\n",
    "\n",
    "        new_entry[\"text\"] = new_text\n",
    "\n",
    "        # We can now change the label to whether the sample is truthful or not\n",
    "        new_entry[\"label\"] = int(is_truthful)\n",
    "\n",
    "        # Remove all other keys\n",
    "        new_entry = { k: v for k, v in new_entry.items() if k in ALLOWED_KEYS }\n",
    "\n",
    "        # Append to the new dataset\n",
    "        new_dataset.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'original_dataset', 'template_name'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = datasets.Dataset.from_list(new_dataset)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally. Which is the topic of this example, choice 1: World politics, or choice 2: Sports? World politics',\n",
       " 'label': 1,\n",
       " 'original_dataset': 'ag_news',\n",
       " 'template_name': 'burns_6'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_idx = 0\n",
    "my_dataset[current_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally. Which is the topic of this example, choice 1: World politics, or choice 2: Sports? World politics\n"
     ]
    }
   ],
   "source": [
    "print(my_dataset[current_idx][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 5010, 0: 4990}),\n",
       " Counter({'ag_news': 1200,\n",
       "          'amazon_polarity': 1200,\n",
       "          'dbpedia_14': 1200,\n",
       "          'glue/qnli': 1200,\n",
       "          'imdb': 1200,\n",
       "          'piqa': 1200,\n",
       "          'super_glue/boolq': 1200,\n",
       "          'super_glue/rte': 1200,\n",
       "          'super_glue/copa': 400}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(my_dataset[\"label\"]), Counter(my_dataset[\"original_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c119d0f2947749269ded308cb1a67b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5636293"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_dataset.to_parquet(f\"datasets/burns_datasets_VINC_{SPLIT}_{VERSION}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 augustas Domain Users 2.8M Jun 29 10:48 burns_datasets_VINC_train_v4.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lah datasets | grep {VERSION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet_data_files = {\n",
    "#     \"train\": \"datasets/my_dataset_train.parquet\",\n",
    "#     \"validation\": \"datasets/my_dataset_validation.parquet\",\n",
    "# }\n",
    "\n",
    "# my_dataset = load_dataset(\"parquet\", data_files=parquet_data_files)\n",
    "# my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
