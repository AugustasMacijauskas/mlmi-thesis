{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../../elk-reporters/gpt2/imdb/jovial-murdock')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../../elk-reporters/gpt2/imdb/jovial-murdock/\")\n",
    "DATA_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VINC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.yaml  fingerprints.yaml  lr_eval.csv  reporters\t  train_lm_eval.csv\n",
      "eval.csv  lm_eval.csv\t     lr_models\t  train_eval.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../../elk-reporters/gpt2/imdb/jovial-murdock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,\n",
       " [PosixPath('../../elk-reporters/gpt2/imdb/jovial-murdock/reporters/layer_0.pt'),\n",
       "  PosixPath('../../elk-reporters/gpt2/imdb/jovial-murdock/reporters/layer_1.pt'),\n",
       "  PosixPath('../../elk-reporters/gpt2/imdb/jovial-murdock/reporters/layer_2.pt'),\n",
       "  PosixPath('../../elk-reporters/gpt2/imdb/jovial-murdock/reporters/layer_3.pt'),\n",
       "  PosixPath('../../elk-reporters/gpt2/imdb/jovial-murdock/reporters/layer_4.pt')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in (DATA_DIR / \"reporters\").iterdir() if f.suffix == \".pt\"]\n",
    "files = sorted(files, key=lambda x: int(x.stem.split(\"_\")[-1]))\n",
    "len(files), files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0.pt\n",
      "2\n",
      "768\n",
      "bias torch.Size([1])\n",
      "scale torch.Size([1])\n",
      "weight torch.Size([1, 768])\n",
      "norm.mean_x torch.Size([768])\n",
      "norm.mean_y torch.Size([1])\n",
      "norm.u torch.Size([768, 1])\n",
      "norm.x_M2 torch.Size([768])\n",
      "norm.xcov_M2 torch.Size([768, 1])\n",
      "norm.y_M2 torch.Size([1])\n",
      "norm.n torch.Size([])\n",
      "-------------\n",
      "\n",
      "layer_1.pt\n",
      "2\n",
      "768\n",
      "bias torch.Size([1])\n",
      "scale torch.Size([1])\n",
      "weight torch.Size([1, 768])\n",
      "norm.mean_x torch.Size([768])\n",
      "norm.mean_y torch.Size([1])\n",
      "norm.u torch.Size([768, 1])\n",
      "norm.x_M2 torch.Size([768])\n",
      "norm.xcov_M2 torch.Size([768, 1])\n",
      "norm.y_M2 torch.Size([1])\n",
      "norm.n torch.Size([])\n",
      "-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in files[:2]:\n",
    "    print(f.name)\n",
    "    tns = torch.load(f)\n",
    "    print(tns[\"num_classes\"])\n",
    "    print(tns[\"in_features\"])\n",
    "\n",
    "    for k, v in tns.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            print(k, v.shape)\n",
    "    \n",
    "    print(\"-------------\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try and load a VINC probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/rds/user/am3052/hpc-work/elk-rlhf/elk')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELK_PATH = Path(\"../../elk/\")\n",
    "ELK_PATH.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/rds/user/am3052/hpc-work/elk-rlhf/src/prototyping',\n",
       " '/home/am3052/.conda/envs/elk/lib/python310.zip',\n",
       " '/home/am3052/.conda/envs/elk/lib/python3.10',\n",
       " '/home/am3052/.conda/envs/elk/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/am3052/.conda/envs/elk/lib/python3.10/site-packages',\n",
       " '__editable__.eleuther_elk-0.1.1.finder.__path_hook__']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/rds/user/am3052/hpc-work/elk-rlhf/elk/elk/training',\n",
       " '/rds/user/am3052/hpc-work/elk-rlhf/elk',\n",
       " '/rds/user/am3052/hpc-work/elk-rlhf/src/prototyping',\n",
       " '/home/am3052/.conda/envs/elk/lib/python310.zip',\n",
       " '/home/am3052/.conda/envs/elk/lib/python3.10',\n",
       " '/home/am3052/.conda/envs/elk/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/am3052/.conda/envs/elk/lib/python3.10/site-packages',\n",
       " '__editable__.eleuther_elk-0.1.1.finder.__path_hook__']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [ELK_PATH, ELK_PATH / \"elk\" / \"training\"]\n",
    "\n",
    "for module in modules:\n",
    "    if not str(module) in sys.path:\n",
    "        sys.path.insert(0, str(module.resolve()))\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reporter import Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/rds/user/am3052/hpc-work/elk-rlhf/elk-reporters/gpt2/imdb/jovial-murdock/reporters/layer_12.pt')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter_path = files[-1]\n",
    "reporter_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EigenReporter(\n",
       "  (norm): SpectralNorm()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter = Reporter.load(reporter_path)\n",
    "reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-14.0780], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0030], requires_grad=True))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.scale, reporter.bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try combining report with a language model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration taken from the [original repository](https://github.com/collin-burns/discovering_latent_knowledge/blob/main/CCS.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_polarity (/home/am3052/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'title', 'content'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"amazon_polarity\", split=\"test[:4]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask']), torch.Size([4, 169]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove label=0\n",
    "def get_prompt(text, label=0):\n",
    "    sentiment = [\"negative\", \"positive\"][label]\n",
    "    return f\"The following movie review expresses a {sentiment} sentiment:\\n{text}\"\n",
    "\n",
    "input_texts = [get_prompt(text) + tokenizer.eos_token for text in dataset[\"content\"]]\n",
    "inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True)\n",
    "inputs.keys(), inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([146, 169,  74,  56])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"attention_mask\"].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRewardModel(nn.Module):\n",
    "    def __init__(self, language_model, reporter, layer=-1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.language_model = language_model\n",
    "        self.reporter = reporter\n",
    "        self.layer = layer\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        hidden_states = self.language_model(\n",
    "            input_ids, attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "        ).hidden_states[self.layer]\n",
    "        \n",
    "        # Find the index of the last non-padding token\n",
    "        last_token_index = torch.sum(attention_mask, dim=1) - 1\n",
    "\n",
    "        # Get the last token's output\n",
    "        last_tokens = hidden_states[range(len(last_token_index)), last_token_index]\n",
    "        print(last_tokens.shape)\n",
    "        \n",
    "        return self.reporter(last_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "my_reward_model = MyRewardModel(language_model, reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    credences = my_reward_model(**inputs)\n",
    "\n",
    "credences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.8509, 10.1446,  9.7738,  9.7631])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
