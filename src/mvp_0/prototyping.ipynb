{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fsx/home-augustas/elk\n",
      "['/fsx/home-augustas/elk/elk/promptsource', '/fsx/home-augustas/elk/elk/training', '/fsx/home-augustas/elk']\n"
     ]
    }
   ],
   "source": [
    "ELK_PATH = Path(\"../../../elk/\")\n",
    "print(ELK_PATH.resolve())\n",
    "\n",
    "modules = [\n",
    "    ELK_PATH,\n",
    "    ELK_PATH / \"elk\" / \"training\",\n",
    "    ELK_PATH / \"elk\" / \"promptsource\",\n",
    "]\n",
    "\n",
    "for module in modules:\n",
    "    if not str(module) in sys.path:\n",
    "        sys.path.insert(0, str(module.resolve()))\n",
    "\n",
    "print(sys.path[:3])\n",
    "\n",
    "from reporter import Reporter\n",
    "from templates import DatasetTemplates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.yaml  fingerprints.yaml  lr_eval.csv  reporters\t  train_lm_eval.csv\n",
      "eval.csv  lm_eval.csv\t     lr_models\t  train_eval.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = (\n",
    "    \"../../../VINC-logs/\"\n",
    "    \"allenai/unifiedqa-v2-t5-11b-1363200/\"\n",
    "    \"AugustasM/burns-datasets-VINC/strange-montalcini\"\n",
    ")\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "\n",
    "!ls {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"allenai/unifiedqa-v2-t5-11b-1363200\"\n",
    "model_name = \"allenai/unifiedqa-v2-t5-3b-1363200\"\n",
    "\n",
    "LAYER = 24"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/admin/home-augustas/.cache/huggingface/datasets/AugustasM___parquet/AugustasM--burns-datasets-VINC-85ec467026b56702/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'original_dataset', 'template_name'],\n",
       "    num_rows: 64\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"AugustasM/burns-datasets-VINC\", split=\"validation[:64]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Consider the text below': <templates.Template object at 0x7f213f2c5de0>, 'Is the given text truthful': <templates.Template object at 0x7f213f2c5e10>, 'Text first': <templates.Template object at 0x7f213f2c5e40>, 'No question no choices': <templates.Template object at 0x7f213f2c4c70>, 'No question with choices': <templates.Template object at 0x7f213f2c5d80>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<templates.Template at 0x7f213f2c5de0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_template_path = \"AugustasM/burns-datasets-VINC/all\"\n",
    "\n",
    "dataset_templates = DatasetTemplates(dataset_template_path)\n",
    "dataset_templates.templates = {\n",
    "    x.name: x for x in dataset_templates.templates.values() if x.get_answer_choices_list(dataset[0]) is not None\n",
    "}\n",
    "print(dataset_templates.templates)\n",
    "\n",
    "template = list(dataset_templates.templates.values())[0]\n",
    "template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'allenai/unifiedqa-v2-t5-3b-1363200'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Tokenizer(name_or_path='allenai/unifiedqa-v2-t5-3b-1363200', vocab_size=32100, model_max_length=512, is_fast=False, padding_side='right', truncation_side='left', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_name, truncation_side=\"left\")\n",
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try combining report with a language model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration taken from the [original repository](https://github.com/collin-burns/discovering_latent_knowledge/blob/main/CCS.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyRewardModel(nn.Module):\n",
    "#     def __init__(\n",
    "#             self, language_model_name, reporter_path,\n",
    "#             layer=-1, device=\"cpu\", hidden_state_name=\"decoder_hidden_states\",\n",
    "#         ):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Load the language model and the reporter\n",
    "#         self.language_model = T5ForConditionalGeneration.from_pretrained(\n",
    "#             language_model_name\n",
    "#         ).to(device)\n",
    "#         self.language_model.eval()\n",
    "\n",
    "#         self.reporter = Reporter.load(reporter_path).to(device)\n",
    "#         self.reporter.eval()\n",
    "\n",
    "#         self.layer = layer # which layer to extract\n",
    "#         self.hidden_state_name = hidden_state_name\n",
    "\n",
    "    \n",
    "#     def forward(self, pos_inputs, neg_inputs):\n",
    "#         # Get the hidden states\n",
    "#         pos_hidden_states = self.language_model(\n",
    "#             **pos_inputs, output_hidden_states=True,\n",
    "#         )[self.hidden_state_name][self.layer]\n",
    "#         neg_hidden_states = self.language_model(\n",
    "#             **neg_inputs, output_hidden_states=True,\n",
    "#         )[self.hidden_state_name][self.layer]\n",
    "        \n",
    "#         # Find the index of the last non-padding token\n",
    "#         pos_last_token_index = torch.sum(pos_inputs[\"attention_mask\"], dim=1) - 1\n",
    "#         neg_last_token_index = torch.sum(neg_inputs[\"attention_mask\"], dim=1) - 1\n",
    "\n",
    "#         # Get the last token's output\n",
    "#         pos_last_tokens = pos_hidden_states[range(len(pos_last_token_index)), pos_last_token_index]\n",
    "#         neg_last_tokens = neg_hidden_states[range(len(neg_last_token_index)), neg_last_token_index]\n",
    "\n",
    "#         # Get the logits for the two classes\n",
    "#         pos_logits = self.reporter(pos_last_tokens)\n",
    "#         neg_logits = self.reporter(neg_last_tokens)\n",
    "\n",
    "#         # Return the difference in logits which will later be\n",
    "#         # passed through a sigmoid function\n",
    "#         return pos_logits - neg_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRewardModel(nn.Module):\n",
    "    def __init__(\n",
    "            self, language_model, reporter_path,\n",
    "            layer=-1, device=\"cpu\", hidden_state_name=\"decoder_hidden_states\",\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load the language model and the reporter\n",
    "        # self.language_model = T5ForConditionalGeneration.from_pretrained(\n",
    "        #     language_model\n",
    "        # ).to(device)\n",
    "        # self.language_model.eval()\n",
    "        self.language_model = language_model\n",
    "\n",
    "        self.reporter = Reporter.load(reporter_path).to(device)\n",
    "        self.reporter.eval()\n",
    "\n",
    "        self.layer = layer # which layer to extract\n",
    "        self.hidden_state_name = hidden_state_name\n",
    "\n",
    "    \n",
    "    def forward(self, pos_inputs, neg_inputs):\n",
    "        '''\n",
    "            NOTE: only works for a single input at a time for now\n",
    "        '''\n",
    "\n",
    "        # Get the hidden states\n",
    "        pos_hidden_states = self.language_model(\n",
    "            **pos_inputs, output_hidden_states=True,\n",
    "        )[self.hidden_state_name][self.layer]\n",
    "        neg_hidden_states = self.language_model(\n",
    "            **neg_inputs, output_hidden_states=True,\n",
    "        )[self.hidden_state_name][self.layer]\n",
    "\n",
    "        # Get the last token's output\n",
    "        # Shape B x T x H -> B x H\n",
    "        pos_last_tokens = pos_hidden_states[:, -1, :]\n",
    "        neg_last_tokens = neg_hidden_states[:, -1, :]\n",
    "\n",
    "        # Get the logits for the two classes\n",
    "        # Shape B x H -> B\n",
    "        pos_logits = self.reporter(pos_last_tokens)\n",
    "        neg_logits = self.reporter(neg_last_tokens)\n",
    "\n",
    "        # Return the difference in logits which will later be\n",
    "        # passed through a sigmoid function\n",
    "        return pos_logits - neg_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/fsx/home-augustas/VINC-logs/allenai/unifiedqa-v2-t5-11b-1363200/AugustasM/burns-datasets-VINC/strange-montalcini/reporters/layer_24.pt')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter_path = DATA_DIR / \"reporters\" / f\"layer_{LAYER}.pt\"\n",
    "reporter_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79.3 ms, sys: 0 ns, total: 79.3 ms\n",
      "Wall time: 8.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reward_model = MyRewardModel(model, reporter_path, layer=LAYER, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "item_copy = item.copy()\n",
    "\n",
    "# Get the positive and negative examples\n",
    "item_copy[\"label\"] = 1\n",
    "pos_q, pos_a = template.apply(item_copy)\n",
    "\n",
    "item_copy[\"label\"] = 0\n",
    "neg_q, neg_a = template.apply(item_copy)\n",
    "\n",
    "# Tokenize the inputs\n",
    "pos_inputs = tokenization_function(pos_q, pos_a).to(device)\n",
    "neg_inputs = tokenization_function(neg_q, neg_a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2552], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = reward_model(pos_inputs, neg_inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sift through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_function = lambda q, a: tokenizer(\n",
    "    q, text_target=a.strip(),\n",
    "    add_special_tokens=True, return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2552218437194824\n",
      "0.3841745853424072\n",
      "0.3256509304046631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28431081771850586\n",
      "0.37639713287353516\n",
      "0.37061095237731934\n",
      "0.28977108001708984\n",
      "0.36952924728393555\n",
      "0.3606541156768799\n",
      "0.255687952041626\n",
      "0.3672020435333252\n",
      "0.35164308547973633\n",
      "0.2697887420654297\n",
      "0.3173236846923828\n",
      "0.3689241409301758\n",
      "0.40074586868286133\n",
      "0.28209733963012695\n",
      "0.30278587341308594\n",
      "0.22183847427368164\n",
      "0.30509042739868164\n",
      "0.21025776863098145\n",
      "0.3518798351287842\n",
      "0.1934523582458496\n",
      "0.30237603187561035\n",
      "0.26209402084350586\n",
      "0.35160207748413086\n",
      "0.23949551582336426\n",
      "0.3721284866333008\n",
      "0.2751791477203369\n",
      "0.32799458503723145\n",
      "0.36185717582702637\n",
      "0.2610764503479004\n",
      "0.31461048126220703\n",
      "0.34275054931640625\n",
      "0.271038293838501\n",
      "0.30406808853149414\n",
      "0.2901172637939453\n",
      "0.35800886154174805\n",
      "0.2638258934020996\n",
      "0.3245968818664551\n",
      "0.3276844024658203\n",
      "0.3547680377960205\n",
      "0.43056797981262207\n",
      "0.4248487949371338\n",
      "0.3674638271331787\n",
      "0.35486602783203125\n",
      "0.4332923889160156\n",
      "0.31902360916137695\n",
      "0.22350382804870605\n",
      "0.22410941123962402\n",
      "0.34844207763671875\n",
      "0.3510615825653076\n",
      "0.2791781425476074\n",
      "0.28778505325317383\n",
      "0.32562255859375\n",
      "0.3204684257507324\n",
      "0.1264967918395996\n",
      "0.37200498580932617\n",
      "0.39983367919921875\n",
      "0.34560108184814453\n",
      "0.311115026473999\n",
      "0.32098865509033203\n",
      "0.35144758224487305\n",
      "0.18973207473754883\n",
      "CPU times: user 5.87 s, sys: 24.3 ms, total: 5.89 s\n",
      "Wall time: 5.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.2552218437194824,\n",
       "  0.3841745853424072,\n",
       "  0.3256509304046631,\n",
       "  0.28431081771850586,\n",
       "  0.37639713287353516,\n",
       "  0.37061095237731934,\n",
       "  0.28977108001708984,\n",
       "  0.36952924728393555,\n",
       "  0.3606541156768799,\n",
       "  0.255687952041626,\n",
       "  0.3672020435333252,\n",
       "  0.35164308547973633,\n",
       "  0.2697887420654297,\n",
       "  0.3173236846923828,\n",
       "  0.3689241409301758,\n",
       "  0.40074586868286133,\n",
       "  0.28209733963012695,\n",
       "  0.30278587341308594,\n",
       "  0.22183847427368164,\n",
       "  0.30509042739868164,\n",
       "  0.21025776863098145,\n",
       "  0.3518798351287842,\n",
       "  0.1934523582458496,\n",
       "  0.30237603187561035,\n",
       "  0.26209402084350586,\n",
       "  0.35160207748413086,\n",
       "  0.23949551582336426,\n",
       "  0.3721284866333008,\n",
       "  0.2751791477203369,\n",
       "  0.32799458503723145,\n",
       "  0.36185717582702637,\n",
       "  0.2610764503479004,\n",
       "  0.31461048126220703,\n",
       "  0.34275054931640625,\n",
       "  0.271038293838501,\n",
       "  0.30406808853149414,\n",
       "  0.2901172637939453,\n",
       "  0.35800886154174805,\n",
       "  0.2638258934020996,\n",
       "  0.3245968818664551,\n",
       "  0.3276844024658203,\n",
       "  0.3547680377960205,\n",
       "  0.43056797981262207,\n",
       "  0.4248487949371338,\n",
       "  0.3674638271331787,\n",
       "  0.35486602783203125,\n",
       "  0.4332923889160156,\n",
       "  0.31902360916137695,\n",
       "  0.22350382804870605,\n",
       "  0.22410941123962402,\n",
       "  0.34844207763671875,\n",
       "  0.3510615825653076,\n",
       "  0.2791781425476074,\n",
       "  0.28778505325317383,\n",
       "  0.32562255859375,\n",
       "  0.3204684257507324,\n",
       "  0.1264967918395996,\n",
       "  0.37200498580932617,\n",
       "  0.39983367919921875,\n",
       "  0.34560108184814453,\n",
       "  0.311115026473999,\n",
       "  0.32098865509033203,\n",
       "  0.35144758224487305,\n",
       "  0.18973207473754883],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "for idx, item in enumerate(dataset):\n",
    "    labels.append(item[\"label\"])\n",
    "    item_copy = item.copy()\n",
    "\n",
    "    # Get the positive and negative examples\n",
    "    item_copy[\"label\"] = 1\n",
    "    pos_q, pos_a = template.apply(item_copy)\n",
    "\n",
    "    item_copy[\"label\"] = 0\n",
    "    neg_q, neg_a = template.apply(item_copy)\n",
    "\n",
    "    # Tokenize the inputs\n",
    "    pos_inputs = tokenization_function(pos_q, pos_a).to(device)\n",
    "    neg_inputs = tokenization_function(neg_q, neg_a).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = reward_model(pos_inputs, neg_inputs)\n",
    "    \n",
    "    print(prediction.item())\n",
    "    predictions.append(prediction.item())\n",
    "\n",
    "# predictions = torch.tensor(predictions)\n",
    "predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider the text below in triple backticks: \n",
      "``` \n",
      "Consider the following example: ''' Chicken Genome Sheds New Light on Human DNA A new study states that 60 of the genes in chicken have close relations to human DNA. This may not comfort those who frequently eat the creature, but may ponder this the next time they order a batch of chicken wings. ''' Choice 1: Science and technology. Choice 2: Business.Between choice 1 and choice 2, what is the topic of this example? Business \n",
      "``` \n",
      "\n",
      "Question: is the given text truthful? Answer either yes or no. \n",
      "Answer:no\n",
      "Consider the text below in triple backticks: \n",
      "``` \n",
      "Consider the following example: ''' Chicken Genome Sheds New Light on Human DNA A new study states that 60 of the genes in chicken have close relations to human DNA. This may not comfort those who frequently eat the creature, but may ponder this the next time they order a batch of chicken wings. ''' Choice 1: Science and technology. Choice 2: Business.Between choice 1 and choice 2, what is the topic of this example? Business \n",
      "``` \n",
      "\n",
      "Question: is the given text truthful? Answer either yes or no. \n",
      "Answer:yes\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(template, entry, label):\n",
    "    entry_copy = entry.copy()\n",
    "    entry_copy[\"label\"] = label\n",
    "\n",
    "    return \"\".join(template.apply(entry_copy))\n",
    "\n",
    "\n",
    "print(get_prompt(template, dataset[0], label=0))\n",
    "print(get_prompt(template, dataset[0], label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 199]), torch.Size([32, 200]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input texts\n",
    "pos_input_texts = [get_prompt(template, item, label=1) for item in dataset]\n",
    "neg_input_texts = [get_prompt(template, item, label=0) for item in dataset]\n",
    "\n",
    "# Get the inputs (input_ids and attention_masks) for the positive and negative texts\n",
    "pos_inputs = tokenizer(pos_input_texts, return_tensors=\"pt\", padding=True)\n",
    "neg_inputs = tokenizer(neg_input_texts, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "pos_inputs[\"input_ids\"].shape, neg_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([136, 109, 133, 112, 142, 124,  96, 122,  98, 113, 135, 115, 161, 113,\n",
       "         138,  89, 147, 108, 155, 199, 125,  89, 116, 125, 119, 116, 101, 132,\n",
       "         111, 113, 114, 126]),\n",
       " tensor([137, 110, 134, 113, 143, 125,  97, 123,  99, 114, 136, 116, 162, 114,\n",
       "         139,  90, 148, 109, 156, 200, 126,  90, 117, 126, 120, 117, 102, 133,\n",
       "         112, 114, 115, 127]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_inputs[\"attention_mask\"].sum(dim=1), neg_inputs[\"attention_mask\"].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = T5ForConditionalGeneration.from_pretrained(\"gpt2\")\n",
    "reporter = Reporter.load(reporter_path)\n",
    "\n",
    "my_reward_model = MyRewardModel(language_model, reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5005, 0.5015, 0.4993, 0.5002])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    credences = my_reward_model(pos_inputs, neg_inputs)\n",
    "\n",
    "outputs = torch.sigmoid(credences)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 0, 1], [1, 1, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare ground-truth with predictions\n",
    "dataset[\"label\"], (outputs > 0.5).int().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
